import asyncio
import aiohttp
import random
import urllib.parse
import logging
import json
import re
import os
from datetime import datetime, timedelta
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes
import google.generativeai as genai
import openai
from typing import Dict, List, Optional
from collections import deque
import httpx

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
from dotenv import load_dotenv
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
TMDB_API_KEY = os.getenv("TMDB_API_KEY")
OMDB_API_KEY = os.getenv("OMDB_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ADMIN_CHAT_ID = os.getenv("ADMIN_CHAT_ID")
CHANNEL_ID = os.getenv("CHANNEL_ID")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Open AI
openai.api_key = OPENAI_API_KEY
client = openai.AsyncOpenAI()

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Google Gemini
genai.configure(api_key=GOOGLE_API_KEY)

# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú˜Ø§Ù†Ø±Ù‡Ø§
GENRE_TRANSLATIONS = {
    'Action': 'Ø§Ú©Ø´Ù†',
    'Adventure': 'Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒÛŒ',
    'Animation': 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†',
    'Comedy': 'Ú©Ù…Ø¯ÛŒ',
    'Crime': 'Ø¬Ù†Ø§ÛŒÛŒ',
    'Documentary': 'Ù…Ø³ØªÙ†Ø¯',
    'Drama': 'Ø¯Ø±Ø§Ù…',
    'Family': 'Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ',
    'Fantasy': 'ÙØ§Ù†ØªØ²ÛŒ',
    'History': 'ØªØ§Ø±ÛŒØ®ÛŒ',
    'Horror': 'ØªØ±Ø³Ù†Ø§Ú©',
    'Music': 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ',
    'Mystery': 'Ø±Ø§Ø²Ø¢Ù„ÙˆØ¯',
    'Romance': 'Ø¹Ø§Ø´Ù‚Ø§Ù†Ù‡',
    'Science Fiction': 'Ø¹Ù„Ù…ÛŒ-ØªØ®ÛŒÙ„ÛŒ',
    'Thriller': 'Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ²',
    'War': 'Ø¬Ù†Ú¯ÛŒ',
    'Western': 'ÙˆØ³ØªØ±Ù†'
}

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ
api_errors: Dict[str, int] = {'tmdb': 0, 'omdb': 0, 'groq': 0, 'gemini': 0, 'deepseek': 0, 'openai': 0}
api_availability: Dict[str, bool] = {'tmdb': True, 'omdb': True, 'groq': True, 'gemini': True, 'deepseek': True, 'openai': True}
previous_comments: List[str] = deque(maxlen=10)
posted_movies: List[str] = []
min_chars = 300
max_chars = 500

# ÙØ§Ù„â€ŒØ¨Ú©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ø¸Ø±Ø§Øª
FALLBACK_COMMENTS = {
    'Ø§Ú©Ø´Ù†': 'Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ø§ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù†ÙØ³â€ŒÚ¯ÛŒØ± Ùˆ Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ² Ø®ÙˆØ¯ØŒ Ù…Ø®Ø§Ø·Ø¨ Ø±Ø§ Ø¨Ù‡ Ø³ÙØ±ÛŒ Ù¾Ø± Ø§Ø² Ø¢Ø¯Ø±Ù†Ø§Ù„ÛŒÙ† Ù…ÛŒâ€ŒØ¨Ø±Ø¯. Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù¾ÙˆÛŒØ§ Ùˆ Ø¬Ù„ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ù‡ Ø®ÛŒØ±Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ ØªØ¬Ø±Ø¨Ù‡â€ŒØ§ÛŒ ÙØ±Ø§Ù…ÙˆØ´â€ŒÙ†Ø´Ø¯Ù†ÛŒ Ø®Ù„Ù‚ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ù¾Ø±Ø´ØªØ§Ø¨ Ú©Ù‡ ØªØ§ Ø¢Ø®Ø±ÛŒÙ† Ù„Ø­Ø¸Ù‡ Ø´Ù…Ø§ Ø±Ø§ Ù…ÛŒØ®Ú©ÙˆØ¨ Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±Ø¯.',
    'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†': 'Ø¬Ù‡Ø§Ù†ÛŒ Ø±Ù†Ú¯Ø§Ø±Ù†Ú¯ Ùˆ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ú©Ù‡ Ù‚Ù„Ø¨ Ùˆ Ø°Ù‡Ù† Ù‡Ø± Ø¨ÛŒÙ†Ù†Ø¯Ù‡â€ŒØ§ÛŒ Ø±Ø§ ØªØ³Ø®ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø§Ø³ØªØ§Ù†â€ŒÚ¯ÙˆÛŒÛŒ Ø¹Ù…ÛŒÙ‚ Ùˆ Ø´Ø®ØµÛŒØªâ€ŒÙ¾Ø±Ø¯Ø§Ø²ÛŒ Ø¬Ø°Ø§Ø¨ØŒ Ø§ÛŒÙ† Ø§Ø«Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø³Ù†ÛŒÙ† Ø¯ÛŒØ¯Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ù¾ÛŒØ§Ù…ÛŒ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´ Ú©Ù‡ Ø¨Ø§ ØªØµØ§ÙˆÛŒØ±ÛŒ Ø´Ú¯ÙØªâ€ŒØ§Ù†Ú¯ÛŒØ² Ù‡Ù…Ø±Ø§Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.',
    'Ú©Ù…Ø¯ÛŒ': 'Ø®Ù†Ø¯Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ø§Ø² ØªÙ‡ Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø·Ù†Ø²Ø¢Ù…ÛŒØ² Ùˆ Ø¯ÛŒØ§Ù„ÙˆÚ¯â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡. Ø¨Ø§Ø²ÛŒÚ¯Ø±Ø§Ù† Ø¨Ø§ Ø´ÛŒÙ…ÛŒ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡ØŒ Ù„Ø­Ø¸Ø§ØªÛŒ Ø´Ø§Ø¯ Ùˆ Ø¨Ù‡â€ŒÛŒØ§Ø¯Ù…Ø§Ù†Ø¯Ù†ÛŒ Ø®Ù„Ù‚ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. ÙÛŒÙ„Ù…ÛŒ Ú©Ù‡ Ø±ÙˆØ­ÛŒÙ‡â€ŒØªØ§Ù† Ø±Ø§ ØªØ§Ø²Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù„Ø¨Ø®Ù†Ø¯ Ø±Ø§ Ø¨Ù‡ Ù„Ø¨Ø§Ù†ØªØ§Ù† Ù…ÛŒâ€ŒØ¢ÙˆØ±Ø¯.',
    'Ø¯Ø±Ø§Ù…': 'Ø±ÙˆØ§ÛŒØªÛŒ Ø¹Ù…ÛŒÙ‚ Ùˆ ØªØ£Ø«ÛŒØ±Ú¯Ø°Ø§Ø± Ú©Ù‡ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø±Ø§ Ø¨Ù‡ Ú†Ø§Ù„Ø´ Ù…ÛŒâ€ŒÚ©Ø´Ø¯. Ø¨Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®Ø´Ø§Ù† Ùˆ Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ø­Ø³Ø§Ø³ØŒ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø§Ù†Ø³Ø§Ù†ÛŒ Ø±Ø§ Ø¨Ù‡ ØªØµÙˆÛŒØ± Ù…ÛŒâ€ŒÚ©Ø´Ù†Ø¯. ÙÛŒÙ„Ù…ÛŒ Ú©Ù‡ ØªØ§ Ù…Ø¯Øªâ€ŒÙ‡Ø§ Ø¯Ø± Ø°Ù‡Ù† Ùˆ Ù‚Ù„Ø¨ Ø´Ù…Ø§ Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯.',
    'Ø³Ø§ÛŒØ±': 'Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ù…Ù†Ø­ØµØ±Ø¨Ù‡â€ŒÙØ±Ø¯ Ú©Ù‡ Ø¨Ø§ Ø±ÙˆØ§ÛŒØªÛŒ Ú¯ÛŒØ±Ø§ Ø´Ù…Ø§ Ø±Ø§ Ù…Ø¬Ø°ÙˆØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² Ø§Ø­Ø³Ø§Ø³Ø§Øª Ùˆ Ø®Ù„Ø§Ù‚ÛŒØª Ú©Ù‡ ØªØ¬Ø±Ø¨Ù‡â€ŒØ§ÛŒ Ù…ØªÙØ§ÙˆØª Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯. Ø§Ø«Ø±ÛŒ Ú©Ù‡ Ø´Ø§ÛŒØ³ØªÙ‡ ØªÙ…Ø§Ø´Ø§ Ùˆ ØªØ£Ù…Ù„ Ø§Ø³Øª.'
}

# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
def is_farsi(text: str) -> bool:
    farsi_chars = r'[\u0600-\u06FF]'
    return bool(re.search(farsi_chars, text))

async def make_api_request(url: str, retries: int = 3) -> Optional[Dict]:
    for attempt in range(retries):
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(url)
                response.raise_for_status()
                return response.json()
        except httpx.HTTPStatusError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ HTTP Ø¯Ø± {url}: {e}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(2 ** attempt)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ {url}: {e}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(2 ** attempt)
    return None

async def post_api_request(url: str, data: Dict, headers: Dict, retries: int = 3) -> Optional[Dict]:
    for attempt in range(retries):
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(url, json=data, headers=headers)
                response.raise_for_status()
                return response.json()
        except httpx.HTTPStatusError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ HTTP Ø¯Ø± POST Ø¨Ù‡ {url}: {e}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(2 ** attempt)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± POST Ø¨Ù‡ {url}: {e}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(2 ** attempt)
    return None

def limit_text_length(text, min_chars=300, max_chars=500):
    text = text.strip()
    text = re.sub(r'\s+', ' ', text.replace('\u200C', ' ').replace('\u200F', ' '))
    if len(text) > max_chars:
        shortened = text[:max_chars]
        last_period = shortened.rfind('.')
        if last_period > min_chars:
            text = shortened[:last_period + 1]
        else:
            text = shortened[:max_chars].strip() + '...'
    if len(text) < min_chars:
        logger.warning(f"Ù…ØªÙ† Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª: {len(text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    return text

def get_fallback_by_genre(fallbacks: Dict[str, str], genres: List[str]) -> str:
    for genre in genres:
        if genre in fallbacks:
            return fallbacks[genre]
    return fallbacks['Ø³Ø§ÛŒØ±']

async def send_admin_alert(update: Update, message: str):
    if ADMIN_CHAT_ID:
        try:
            app = update.application if update else Application.builder().token(BOT_TOKEN).build()
            await app.bot.send_message(chat_id=ADMIN_CHAT_ID, text=message)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†: {e}")

async def get_imdb_score_tmdb(title: str, genres: Optional[List[str]] = None) -> Optional[str]:
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª TMDB Ø¨Ø±Ø§ÛŒ: {title}")
    encoded_title = urllib.parse.quote(title)
    url = f"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={encoded_title}&language=en-US"
    data = await make_api_request(url)
    if not data or not data.get('results'):
        logger.warning(f"TMDB Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯")
        api_errors['tmdb'] += 1
        return None
    movie = data['results'][0]
    imdb_score = movie.get('vote_average', 0)
    
    is_animation = False
    if genres:
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    else:
        details_url = f"https://api.themoviedb.org/3/movie/{movie.get('id')}?api_key={TMDB_API_KEY}&language=en-US"
        details_data = await make_api_request(details_url)
        genres = [GENRE_TRANSLATIONS.get(g['name'], 'Ø³Ø§ÛŒØ±') for g in details_data.get('genres', [])]
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    
    min_score = 8.0 if is_animation else 6.0
    if imdb_score < min_score:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯ (Ø­Ø¯Ø§Ù‚Ù„ {min_score} Ù„Ø§Ø²Ù… Ø§Ø³Øª)")
        return None
    api_errors['tmdb'] = 0
    return f"{float(imdb_score):.1f}/10"

async def get_imdb_score_omdb(title: str, genres: Optional[List[str]] = None) -> Optional[str]:
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª OMDb Ø¨Ø±Ø§ÛŒ: {title}")
    encoded_title = urllib.parse.quote(title)
    url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={encoded_title}&type=movie"
    data = await make_api_request(url)
    if not data or data.get('Response') == 'False':
        logger.warning(f"OMDb Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯: {data.get('Error')}")
        api_errors['omdb'] += 1
        return None
    imdb_score = data.get('imdbRating', '0')
    
    is_animation = False
    if genres:
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    else:
        genres = data.get('Genre', '').split(', ')
        genres = [GENRE_TRANSLATIONS.get(g.strip(), 'Ø³Ø§ÛŒØ±') for g in genres]
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    
    min_score = 8.0 if is_animation else 6.0
    if float(imdb_score) < min_score:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯ (Ø­Ø¯Ø§Ù‚Ù„ {min_score} Ù„Ø§Ø²Ù… Ø§Ø³Øª)")
        return None
    api_errors['omdb'] = 0
    return f"{float(imdb_score):.1f}/10"

async def get_movie_info(title: str, genres: Optional[List[str]] = None) -> Optional[Dict]:
    score = None
    if api_availability['tmdb'] and api_errors['tmdb'] < 3:
        logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ TMDB Ø¨Ø±Ø§ÛŒ {title}")
        score = await get_imdb_score_tmdb(title, genres)
    if not score and api_availability['omdb'] and api_errors['omdb'] < 3:
        logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ OMDb Ø¨Ø±Ø§ÛŒ {title}")
        score = await get_imdb_score_omdb(title, genres)
    if not score:
        logger.warning(f"Ù‡ÛŒÚ† Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        return None
    
    if not genres:
        url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={urllib.parse.quote(title)}&type=movie"
        data = await make_api_request(url)
        if data and data.get('Response') == 'True':
            genres = data.get('Genre', '').split(', ')
            genres = [GENRE_TRANSLATIONS.get(g.strip(), 'Ø³Ø§ÛŒØ±') for g in genres]
    
    return {'title': title, 'score': score, 'genres': genres}

async def generate_comment(genres: List[str]) -> str:
    logger.info("ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„...")

    if api_availability['gemini']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ Gemini")
        try:
            async with asyncio.timeout(10):
                model = genai.GenerativeModel('gemini-1.5-flash')
                prompt = "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."
                response = await model.generate_content_async(prompt)
                text = response.text.strip()
                text = limit_text_length(text)
                logger.info(f"ØªØ­Ù„ÛŒÙ„ Gemini: {text}")
                logger.info(f"Ø·ÙˆÙ„ Ù…ØªÙ†: {len(text)}, ÙØ§Ø±Ø³ÛŒ: {is_farsi(text)}")
                if min_chars <= len(text) <= max_chars and is_farsi(text):
                    previous_comments.append(text)
                    if len(previous_comments) > 10:
                        previous_comments.pop(0)
                    logger.info("ØªØ­Ù„ÛŒÙ„ Gemini Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    return text
                logger.warning(f"ØªØ­Ù„ÛŒÙ„ Gemini Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
        except google_exceptions.ResourceExhausted:
            logger.error("Ø®Ø·Ø§: ØªÙˆÚ©Ù† Gemini ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª")
            api_availability['gemini'] = False
            await send_admin_alert(None, "âŒ ØªÙˆÚ©Ù† Gemini ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Gemini API: {str(e)}")
            api_availability['gemini'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Gemini: {str(e)}.")

    if api_availability['groq']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ Groq")
        try:
            async with asyncio.timeout(10):
                url = "https://api.groq.com/openai/v1/chat/completions"
                headers = {
                    "Authorization": f"Bearer {GROQ_API_KEY}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "mistral-saba-24b",
                    "messages": [
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    "max_tokens": 200,
                    "temperature": 0.9
                }
                response = await post_api_request(url, data, headers, retries=3)
                if response and response.get('choices'):
                    text = response['choices'][0]['message']['content'].strip()
                    text = limit_text_length(text)
                    if min_chars <= len(text) <= max_chars and is_farsi(text):
                        previous_comments.append(text)
                        if len(previous_comments) > 10:
                            previous_comments.pop(0)
                        logger.info("ØªØ­Ù„ÛŒÙ„ Groq Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                        return text
                    logger.warning(f"ØªØ­Ù„ÛŒÙ„ Groq Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
                else:
                    logger.warning(f"Ù¾Ø§Ø³Ø® Groq Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {response}")
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Groq: {str(e)}")
            api_availability['groq'] = False
            await send_admin_alert(None, f"âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Groq: {str(e)}.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Groq API: {str(e)}")
            api_availability['groq'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Groq: {str(e)}.")

    if api_availability['deepseek']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ DeepSeek")
        try:
            async with asyncio.timeout(10):
                url = "https://api.deepseek.com/v1/chat/completions"
                headers = {
                    "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    "max_tokens": 200,
                    "temperature": 0.9
                }
                response = await post_api_request(url, data, headers, retries=3)
                if response and response.get('choices'):
                    text = response['choices'][0]['message']['content'].strip()
                    text = limit_text_length(text)
                    if min_chars <= len(text) <= max_chars and is_farsi(text):
                        previous_comments.append(text)
                        if len(previous_comments) > 10:
                            previous_comments.pop(0)
                        logger.info("ØªØ­Ù„ÛŒÙ„ DeepSeek Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                        return text
                    logger.warning(f"ØªØ­Ù„ÛŒÙ„ DeepSeek Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
                else:
                    logger.warning(f"Ù¾Ø§Ø³Ø® DeepSeek Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {response}")
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ DeepSeek: {str(e)}")
            api_availability['deepseek'] = False
            await send_admin_alert(None, f"âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ DeepSeek: {str(e)}.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± DeepSeek API: {str(e)}")
            api_availability['deepseek'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± DeepSeek: {str(e)}.")

    if api_availability['openai']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ Open AI")
        try:
            async with asyncio.timeout(10):
                response = await client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    max_tokens=200,
                    temperature=0.9
                )
                text = response.choices[0].message.content.strip()
                text = limit_text_length(text)
                if min_chars <= len(text) <= max_chars and is_farsi(text):
                    previous_comments.append(text)
                    if len(previous_comments) > 10:
                        previous_comments.pop(0)
                    logger.info("ØªØ­Ù„ÛŒÙ„ Open AI Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    return text
                logger.warning(f"ØªØ­Ù„ÛŒÙ„ Open AI Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Open AI: {str(e)}")
            api_availability['openai'] = False
            await send_admin_alert(None, f"âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Open AI: {str(e)}.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Open AI API: {str(e)}")
            api_availability['openai'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Open AI: {str(e)}.")

    logger.warning("Ù‡ÛŒÚ† ØªØ­Ù„ÛŒÙ„Ú¯Ø±ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
    comment = get_fallback_by_genre(FALLBACK_COMMENTS, genres)
    comment = limit_text_length(comment)
    previous_comments.append(comment)
    if len(previous_comments) > 10:
        previous_comments.pop(0)
    return comment

async def select_random_movie() -> Optional[Dict]:
    logger.info("Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÙ„Ù… ØªØµØ§Ø¯ÙÛŒ...")
    max_attempts = 5
    for attempt in range(max_attempts):
        try:
            page = random.randint(1, 100)
            url = f"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=fa-IR&page={page}"
            data = await make_api_request(url)
            if not data or not data.get('results'):
                logger.warning(f"TMDB Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡ {page} Ù†Ø¯Ø§Ø¯")
                continue
            movies = data['results']
            movie = random.choice(movies)
            title = movie.get('title')
            if title in posted_movies:
                logger.info(f"ÙÛŒÙ„Ù… {title} Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ØŒ ØªÙ„Ø§Ø´ Ø¯ÙˆØ¨Ø§Ø±Ù‡...")
                continue
            genres = [GENRE_TRANSLATIONS.get(g['name'], 'Ø³Ø§ÛŒØ±') for g in movie.get('genres', [])]
            movie_info = await get_movie_info(title, genres)
            if movie_info:
                logger.info(f"ÙÛŒÙ„Ù… Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {title} (ØªÙ„Ø§Ø´ {attempt + 1})")
                return movie_info
            logger.info(f"ÙÛŒÙ„Ù… {title} Ø±Ø¯ Ø´Ø¯ØŒ ØªÙ„Ø§Ø´ Ø¯ÙˆØ¨Ø§Ø±Ù‡...")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÙ„Ù…: {e}")
            if attempt == max_attempts - 1:
                await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÙ„Ù… Ù¾Ø³ Ø§Ø² {max_attempts} ØªÙ„Ø§Ø´: {str(e)}.")
    logger.error("Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯")
    return None

async def save_posted_movies():
    try:
        with open('posted_movies.json', 'w', encoding='utf-8') as f:
            json.dump(posted_movies, f, ensure_ascii=False, indent=2)
        logger.info(f"Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {len(posted_movies)} ÙÛŒÙ„Ù…")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {e}")

async def load_posted_movies():
    global posted_movies
    try:
        with open('posted_movies.json', 'r', encoding='utf-8') as f:
            posted_movies = json.load(f)
        logger.info(f"Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {len(posted_movies)} ÙÛŒÙ„Ù…")
    except FileNotFoundError:
        logger.info("ÙØ§ÛŒÙ„ posted_movies.json ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø´Ø±ÙˆØ¹ Ø¨Ø§ Ù„ÛŒØ³Øª Ø®Ø§Ù„ÛŒ")
        posted_movies = []
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {e}")
        posted_movies = []

async def post_movie(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logger.info("Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¬Ø¯ÛŒØ¯...")
    movie = await select_random_movie()
    if not movie:
        await send_admin_alert(update, "âŒ Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
        return
    
    title = movie['title']
    score = movie['score']
    genres = movie['genres']
    
    comment = await generate_comment(genres)
    message = f"ğŸ¬ *{title}*\n\nğŸ“Š Ø§Ù…ØªÛŒØ§Ø²: {score}\n\nğŸ’¬ *Ø­Ø±Ù Ù…Ø§*: {comment}"
    
    try:
        sent_message = await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text=message,
            parse_mode='Markdown'
        )
        posted_movies.append(title)
        await save_posted_movies()
        logger.info(f"Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¨Ø±Ø§ÛŒ: {title}")
        
        await asyncio.sleep(60)
        new_comment = await generate_comment(genres)
        updated_message = f"ğŸ¬ *{title}*\n\nğŸ“Š Ø§Ù…ØªÛŒØ§Ø²: {score}\n\nğŸ’¬ *Ø­Ø±Ù Ù…Ø§*: {new_comment}"
        await context.bot.edit_message_text(
            chat_id=CHANNEL_ID,
            message_id=sent_message.message_id,
            text=updated_message,
            parse_mode='Markdown'
        )
        logger.info(f"Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø³Øª Ø¨Ø±Ø§ÛŒ: {title}")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ ÛŒØ§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ù¾Ø³Øª: {e}")
        await send_admin_alert(update, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¨Ø±Ø§ÛŒ {title}: {str(e)}.")

async def run_tests(update: Update, context: ContextTypes.DEFAULT_TYPE):
    results = []

    tmdb_url = f"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=fa-IR&page=1"
    tmdb_data = await make_api_request(tmdb_url)
    tmdb_status = "âœ… TMDB Ø§ÙˆÚ©ÛŒ" if tmdb_data and tmdb_data.get('results') else f"âŒ TMDB Ø®Ø·Ø§: {tmdb_data}"
    results.append(tmdb_status)

    omdb_url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t=Inception&type=movie"
    omdb_data = await make_api_request(omdb_url)
    omdb_status = "âœ… OMDb Ø§ÙˆÚ©ÛŒ" if omdb_data and omdb_data.get('Response') == 'True' else f"âŒ OMDb Ø®Ø·Ø§: {omdb_data.get('Error')}"
    results.append(omdb_status)

    job_queue = context.job_queue
    results.append("âœ… JobQueue ÙØ¹Ø§Ù„" if job_queue else "âŒ JobQueue ØºÛŒØ±ÙØ¹Ø§Ù„")

    if api_availability['gemini']:
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            prompt = "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."
            response = await model.generate_content_async(prompt)
            text = response.text.strip()
            gemini_status = "âœ… Gemini Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else "âŒ Gemini Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
            results.append(gemini_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Gemini: {str(e)}")
            api_availability['gemini'] = False
            results.append(f"âŒ Gemini Ø®Ø·Ø§: {str(e)}")

    if api_availability['groq']:
        try:
            url = "https://api.groq.com/openai/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": "mistral-saba-24b",
                "messages": [
                    {"role": "system", "content": "Write in Persian."},
                    {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                "max_tokens": 50,
                "temperature": 0.9
            }
            response = await post_api_request(url, data, headers, retries=3)
            text = response['choices'][0]['message']['content'].strip() if response and response.get('choices') else ""
            groq_status = "âœ… Groq Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else f"âŒ Groq Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± - Ù…ØªÙ† Ø¯Ø±ÛŒØ§ÙØªÛŒ: {text}"
            results.append(groq_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Groq: {str(e)}")
            api_availability['groq'] = False
            results.append(f"âŒ Groq Ø®Ø·Ø§: {str(e)}")

    if api_availability['deepseek']:
        try:
            url = "https://api.deepseek.com/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "Write in Persian."},
                    {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                "max_tokens": 50,
                "temperature": 0.9
            }
            response = await post_api_request(url, data, headers, retries=3)
            text = response['choices'][0]['message']['content'].strip() if response and response.get('choices') else ""
            deepseek_status = "âœ… DeepSeek Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else f"âŒ DeepSeek Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± - Ù…ØªÙ† Ø¯Ø±ÛŒØ§ÙØªÛŒ: {text}"
            results.append(deepseek_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª DeepSeek: {str(e)}")
            api_availability['deepseek'] = False
            results.append(f"âŒ DeepSeek Ø®Ø·Ø§: {str(e)}")

    if api_availability['openai']:
        try:
            response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Write in Persian."},
                    {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                max_tokens=50,
                temperature=0.9
            )
            text = response.choices[0].message.content.strip()
            openai_status = "âœ… Open AI Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else "âŒ Open AI Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
            results.append(openai_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Open AI: {str(e)}")
            api_availability['openai'] = False
            results.append(f"âŒ Open AI Ø®Ø·Ø§: {str(e)}")

    await update.message.reply_text("\n".join(results))

async def schedule_posts(context: ContextTypes.DEFAULT_TYPE):
    while True:
        try:
            await post_movie(None, context)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù¾Ø³Øª: {e}")
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ù¾Ø³Øª: {str(e)}.")
        await asyncio.sleep(4 * 60 * 60)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ø¨Ø§Øª ÙÛŒÙ„Ù… Ø´Ø±ÙˆØ¹ Ø´Ø¯! Ø¨Ø±Ø§ÛŒ ØªØ³Øª ÙˆØ¶Ø¹ÛŒØª Ø§Ø² /test Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.")

async def main():
    await load_posted_movies()
    app = Application.builder().token(BOT_TOKEN).build()
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("test", run_tests))
    
    app.job_queue.run_once(schedule_posts, 0)
    
    logger.info("Ø¨Ø§Øª Ø´Ø±ÙˆØ¹ Ø´Ø¯")
    await app.run_polling()

if __name__ == '__main__':
    asyncio.run(main())
