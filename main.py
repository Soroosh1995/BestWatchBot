import telegram
import asyncio
import os
import logging
import aiohttp
import random
import google.generativeai as genai
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes
from dotenv import load_dotenv
from aiohttp import web, ClientTimeout
import urllib.parse
from datetime import datetime, timedelta
from google.api_core import exceptions as google_exceptions
from openai import AsyncOpenAI
import aiohttp.client_exceptions
import re
import certifi
import json

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

load_dotenv()
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
CHANNEL_ID = os.getenv('CHANNEL_ID')
ADMIN_ID = os.getenv('ADMIN_ID')
TMDB_API_KEY = os.getenv('TMDB_API_KEY')
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
RAPIDAPI_KEY = os.getenv('RAPIDAPI_KEY')
OMDB_API_KEY = os.getenv('OMDB_API_KEY')
PORT = int(os.getenv('PORT', 8080))
POST_INTERVAL = int(os.getenv('POST_INTERVAL', 600))
FETCH_INTERVAL = int(os.getenv('FETCH_INTERVAL', 86400))

# ØªÙ†Ø¸ÛŒÙ… Gemini
genai.configure(api_key=GOOGLE_API_KEY)

# ØªÙ†Ø¸ÛŒÙ… Open AI
client = AsyncOpenAI(api_key=OPENAI_API_KEY, http_client=aiohttp.ClientSession())

# --- Ú©Ø´ Ùˆ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ ---
cached_movies = []
posted_movies = []
last_fetch_time = datetime.now() - timedelta(days=1)
previous_plots = []
previous_comments = []
gemini_available = True
openai_available = True
bot_enabled = True
CACHE_FILE = "movie_cache.json"
POSTED_MOVIES_FILE = "posted_movies.json"

# --- Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú˜Ø§Ù†Ø±Ù‡Ø§ ---
GENRE_TRANSLATIONS = {
    'Action': 'Ø§Ú©Ø´Ù†',
    'Adventure': 'Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒÛŒ',
    'Animation': 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†',
    'Comedy': 'Ú©Ù…Ø¯ÛŒ',
    'Crime': 'Ø¬Ù†Ø§ÛŒÛŒ',
    'Documentary': 'Ù…Ø³ØªÙ†Ø¯',
    'Drama': 'Ø¯Ø±Ø§Ù…',
    'Family': 'Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ',
    'Fantasy': 'ÙØ§Ù†ØªØ²ÛŒ',
    'History': 'ØªØ§Ø±ÛŒØ®ÛŒ',
    'Horror': 'ØªØ±Ø³Ù†Ø§Ú©',
    'Music': 'Ù…ÙˆØ³ÛŒÙ‚ÛŒ',
    'Mystery': 'Ø±Ø§Ø²Ø¢Ù„ÙˆØ¯',
    'Romance': 'Ø¹Ø§Ø´Ù‚Ø§Ù†Ù‡',
    'Science Fiction': 'Ø¹Ù„Ù…ÛŒ_ØªØ®ÛŒÙ„ÛŒ',
    'Thriller': 'Ù‡ÛŒØ¬Ø§Ù†_Ø§Ù†Ú¯ÛŒØ²',
    'War': 'Ø¬Ù†Ú¯ÛŒ',
    'Western': 'ÙˆØ³ØªØ±Ù†',
    'Unknown': 'Ø³Ø§ÛŒØ±'
}

# --- ÙØ§Ù„â€ŒØ¨Ú©â€ŒÙ‡Ø§ ---
FALLBACK_PLOTS = {
    'Ø§Ú©Ø´Ù†': [
        "Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒÛŒ Ù¾Ø±Ù‡ÛŒØ¬Ø§Ù†ÛŒ Ú©Ù‡ Ù‚Ù‡Ø±Ù…Ø§Ù† Ø¨Ø§ Ø¯Ø´Ù…Ù†Ø§Ù† Ù‚Ø¯Ø±ØªÙ…Ù†Ø¯ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù†Ø¨Ø±Ø¯Ù‡Ø§ÛŒ Ù†ÙØ³â€ŒÚ¯ÛŒØ± Ø´Ù…Ø§ Ø±Ø§ Ù…ÛŒØ®Ú©ÙˆØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¢ÛŒØ§ Ø§Ùˆ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¬Ù‡Ø§Ù† Ø±Ø§ Ù†Ø¬Ø§Øª Ø¯Ù‡Ø¯ØŸ",
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ù¾Ø± Ø§Ø² ØªØ¹Ù‚ÛŒØ¨ Ùˆ Ú¯Ø±ÛŒØ² Ùˆ Ø§Ù†ÙØ¬Ø§Ø±Ù‡Ø§ÛŒ Ù…Ù‡ÛŒØ¬. Ù‚Ù‡Ø±Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ Ø¹Ø¯Ø§Ù„Øª Ù…ÛŒâ€ŒØ¬Ù†Ú¯Ø¯. Ø¢ÛŒØ§ Ø§Ùˆ Ù¾ÛŒØ±ÙˆØ² Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯ØŸ",
    ],
    'Ø¯Ø±Ø§Ù…': [
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø¹Ù…ÛŒÙ‚ Ø§Ø² Ø±ÙˆØ§Ø¨Ø· Ø§Ù†Ø³Ø§Ù†ÛŒ Ùˆ Ø§Ù†ØªØ®Ø§Ø¨â€ŒÙ‡Ø§ÛŒ Ø³Ø®Øª. Ø²Ù†Ø¯Ú¯ÛŒ Ø´Ø®ØµÛŒØªÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ú©Ù‡ Ù‚Ù„Ø¨ Ø´Ù…Ø§ Ø±Ø§ Ù„Ù…Ø³ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¢ÛŒØ§ Ø§Ùˆ Ø±Ø§Ù‡ Ø®ÙˆØ¯ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ø®ÙˆØ§Ù‡Ø¯ Ú©Ø±Ø¯ØŸ",
        "Ø±ÙˆØ§ÛŒØªÛŒ Ø§Ø­Ø³Ø§Ø³ÛŒ Ø§Ø² Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ùˆ Ø¹Ø´Ù‚. ØªØµÙ…ÛŒÙ…â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ Ø±Ø§ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯. Ø¢ÛŒØ§ Ù¾Ø§ÛŒØ§Ù† Ø®ÙˆØ´ÛŒ Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø³ØªØŸ",
    ],
    'Ú©Ù…Ø¯ÛŒ': [
        "Ù…Ø§Ø¬Ø±Ø§Ù‡Ø§ÛŒ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø±ÛŒ Ú©Ù‡ Ø²Ù†Ø¯Ú¯ÛŒ Ø±Ø§ Ø²ÛŒØ±ÙˆØ±Ùˆ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ú¯Ø±ÙˆÙ‡ÛŒ Ø§Ø² Ø¯ÙˆØ³ØªØ§Ù† Ú©Ù‡ Ø¯Ø± Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¹Ø¬ÛŒØ¨ Ú¯ÛŒØ± Ù…ÛŒâ€ŒØ§ÙØªÙ†Ø¯. Ø¢ÛŒØ§ Ø§Ø² Ø§ÛŒÙ† Ù…Ø®Ù…ØµÙ‡ Ø®Ù„Ø§Øµ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ØŸ",
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ù¾Ø± Ø§Ø² Ø´ÙˆØ®ÛŒ Ùˆ Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù…Ø²Ù‡. Ø´Ø®ØµÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø´Ù…Ø§ Ø±Ø§ Ø¨Ù‡ Ø®Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ§Ù†Ø¯Ø§Ø²Ù†Ø¯. Ø¢ÛŒØ§ Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ø¨Ù‡ Ø®ÛŒØ± Ù…ÛŒâ€ŒÚ¯Ø°Ø±Ø¯ØŸ",
    ],
    'Ø¹Ù„Ù…ÛŒ_ØªØ®ÛŒÙ„ÛŒ': [
        "Ø¬Ù‡Ø§Ù†ÛŒ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡ Ú©Ù‡ ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒ Ù‡Ù…Ù‡â€ŒÚ†ÛŒØ² Ø±Ø§ ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯Ù‡. Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒÛŒâ€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù Ø­Ù‚ÛŒÙ‚Øª Ù¾Ø´Øª ÛŒÚ© Ø±Ø§Ø² Ø¨Ø²Ø±Ú¯. Ø¢ÛŒØ§ Ø¨Ø´Ø±ÛŒØª Ù†Ø¬Ø§Øª Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŸ",
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø§Ø² Ø³ÙØ± Ø¯Ø± Ø²Ù…Ø§Ù† Ùˆ ÙØ¶Ø§. Ø§Ú©ØªØ´Ø§ÙØ§ØªÛŒ Ú©Ù‡ Ø¬Ù‡Ø§Ù† Ø±Ø§ Ø¯Ú¯Ø±Ú¯ÙˆÙ† Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. Ø¢ÛŒØ§ Ø­Ù‚ÛŒÙ‚Øª Ø¢Ø´Ú©Ø§Ø± Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯ØŸ",
    ],
    'Ø³Ø§ÛŒØ±': [
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø¬Ø°Ø§Ø¨ Ú©Ù‡ Ø´Ù…Ø§ Ø±Ø§ Ø¨Ù‡ Ø³ÙØ±ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ù…ÛŒâ€ŒØ¨Ø±Ø¯. Ø´Ø®ØµÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¨Ø§ Ú†Ø§Ù„Ø´â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø±ÙˆØ¨Ø±Ùˆ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ø¢ÛŒØ§ Ù¾Ø§ÛŒØ§Ù† Ø®ÙˆØ´ÛŒ Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø³ØªØŸ",
    ]
}

FALLBACK_COMMENTS = {
    'Ø§Ú©Ø´Ù†': [
        "Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ø§ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø´Ù† Ù†ÙØ³â€ŒÚ¯ÛŒØ± Ùˆ Ø¯Ø§Ø³ØªØ§Ù† Ù¾Ø±Ù‡ÛŒØ¬Ø§Ù†ØŒ Ø´Ù…Ø§ Ø±Ø§ Ø¨Ù‡ ØµÙ†Ø¯Ù„ÛŒ Ù…ÛŒØ®Ú©ÙˆØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù¾ÙˆÛŒØ§ Ùˆ Ø¬Ù„ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ø®ÛŒØ±Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¢Ù† Ø§Ø³Øª. ÙÙ‚Ø· Ú¯Ø§Ù‡ÛŒ Ø±ÛŒØªÙ… ØªÙ†Ø¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ÛŒ Ú¯ÛŒØ¬â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.",
        "ÙÛŒÙ„Ù…ÛŒ Ù¾Ø± Ø§Ø² Ù‡ÛŒØ¬Ø§Ù† Ùˆ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø´Ù† ØªÙ…Ø§Ø´Ø§ÛŒÛŒ. Ø¯Ø§Ø³ØªØ§Ù† Ø³Ø±Ú¯Ø±Ù…â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ùˆ Ø¨Ø§Ø²ÛŒÚ¯Ø±ÛŒ Ù‚ÙˆÛŒØŒ Ø¢Ù† Ø±Ø§ Ø¬Ø°Ø§Ø¨ Ú©Ø±Ø¯Ù‡ Ø§Ø³Øª. ÙÙ‚Ø· Ø¨Ø±Ø®ÛŒ Ù„Ø­Ø¸Ø§Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù‚Ø§Ø¨Ù„ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ø§Ø´Ù†Ø¯.",
    ],
    'Ø¯Ø±Ø§Ù…': [
        "Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ø§ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø¹Ù…ÛŒÙ‚ Ùˆ Ø§Ø­Ø³Ø§Ø³ÛŒØŒ Ù‚Ù„Ø¨ Ø´Ù…Ø§ Ø±Ø§ ØªØ³Ø®ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø§Ø²ÛŒÚ¯Ø±ÛŒ Ø¨ÛŒâ€ŒÙ†Ù‚Øµ Ùˆ Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ø­Ø³Ø§Ø³ØŒ Ø¢Ù† Ø±Ø§ Ø¨Ù‡ Ø§Ø«Ø±ÛŒ Ù…Ø§Ù†Ø¯Ú¯Ø§Ø± ØªØ¨Ø¯ÛŒÙ„ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯. ÙÙ‚Ø· Ø±ÛŒØªÙ… Ú©Ù†Ø¯ Ø¨Ø±Ø®ÛŒ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª ØµØ¨Ø± Ø´Ù…Ø§ Ø±Ø§ Ø¨ÛŒØ§Ø²Ù…Ø§ÛŒØ¯.",
        "Ø±ÙˆØ§ÛŒØªÛŒ ØªÚ©Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø§Ø² Ø²Ù†Ø¯Ú¯ÛŒ Ùˆ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø§Ù†Ø³Ø§Ù†ÛŒ. ÙÛŒÙ„Ù…â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ø²ÛŒØ¨Ø§ Ùˆ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù…ØªÙ† ØªØ£Ø«ÛŒØ±Ú¯Ø°Ø§Ø±ØŒ Ø¢Ù† Ø±Ø§ Ø®Ø§Øµ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯. ÙÙ‚Ø· Ù¾Ø§ÛŒØ§Ù† Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ Ø±Ø¶Ø§ÛŒØªâ€ŒØ¨Ø®Ø´ Ù†Ø¨Ø§Ø´Ø¯.",
    ],
    'Ú©Ù…Ø¯ÛŒ': [
        "Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ø§ Ø´ÙˆØ®ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù…Ø²Ù‡ Ùˆ Ø¯Ø§Ø³ØªØ§Ù† Ø³Ø±Ú¯Ø±Ù…â€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ Ø´Ù…Ø§ Ø±Ø§ Ø¨Ù‡ Ø®Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ§Ù†Ø¯Ø§Ø²Ø¯. Ø¨Ø§Ø²ÛŒÚ¯Ø±Ø§Ù† Ø´ÛŒÙ…ÛŒ ÙÙˆÙ‚â€ŒØ§Ù„Ø¹Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù¾Ø±Ø§Ù†Ø±Ú˜ÛŒ Ø§Ø³Øª. ÙÙ‚Ø· Ø¨Ø±Ø®ÛŒ Ø¬ÙˆÚ©â€ŒÙ‡Ø§ Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ø¨Ù‡ Ù†Ø¸Ø± Ø¨Ø±Ø³Ù†Ø¯.",
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø³Ø¨Ú© Ùˆ Ø®Ù†Ø¯Ù‡â€ŒØ¯Ø§Ø± Ú©Ù‡ Ø­Ø§Ù„ Ø´Ù…Ø§ Ø±Ø§ Ø®ÙˆØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø´Ø®ØµÛŒØªâ€ŒÙ¾Ø±Ø¯Ø§Ø²ÛŒ Ù‚ÙˆÛŒ Ùˆ Ø¯ÛŒØ§Ù„ÙˆÚ¯â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ø§Ø² Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¢Ù† Ø§Ø³Øª. ÙÙ‚Ø· Ø±ÛŒØªÙ… Ø¯Ø± Ø¨Ø±Ø®ÛŒ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§ Ø§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.",
    ],
    'Ø¹Ù„Ù…ÛŒ_ØªØ®ÛŒÙ„ÛŒ': [
        "Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ø§ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ Ùˆ Ø¬Ù„ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ø®ÛŒØ±Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ Ø´Ù…Ø§ Ø±Ø§ Ø¨Ù‡ Ø¯Ù†ÛŒØ§ÛŒÛŒ Ø¯ÛŒÚ¯Ø± Ù…ÛŒâ€ŒØ¨Ø±Ø¯. Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ Ùˆ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù…ØªÙ† Ø­Ù…Ø§Ø³ÛŒ Ø§Ø² Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¢Ù† Ø§Ø³Øª. ÙÙ‚Ø· Ø¨Ø±Ø®ÛŒ Ù…ÙØ§Ù‡ÛŒÙ… Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¨Ø§Ø´Ù†Ø¯.",
        "Ø¬Ù‡Ø§Ù†ÛŒ ÙØ§Ù†ØªØ²ÛŒ Ú©Ù‡ Ø¨Ø§ Ø¯Ø§Ø³ØªØ§Ù†â€ŒØ³Ø±Ø§ÛŒÛŒ Ù‚ÙˆÛŒ Ø´Ù…Ø§ Ø±Ø§ Ù…Ø¬Ø°ÙˆØ¨ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ ØªØ®ÛŒÙ„ÛŒ Ùˆ Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ø®Ù„Ø§Ù‚Ø§Ù†Ù‡ØŒ Ø¢Ù† Ø±Ø§ Ø¯ÛŒØ¯Ù†ÛŒ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯. ÙÙ‚Ø· Ø¨Ø±Ø®ÛŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú¯Ù†Ú¯ Ø¨Ø§Ø´Ù†Ø¯.",
    ],
    'Ø³Ø§ÛŒØ±': [
        "ÙÛŒÙ„Ù…ÛŒ Ú©Ù‡ Ø¨Ø§ Ø¯Ø§Ø³ØªØ§Ù†â€ŒØ³Ø±Ø§ÛŒÛŒ Ø¬Ø°Ø§Ø¨ Ùˆ Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù‚ÙˆÛŒØŒ Ø´Ù…Ø§ Ø±Ø§ Ø³Ø±Ú¯Ø±Ù… Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø§Ø²ÛŒÚ¯Ø±ÛŒ Ø®ÙˆØ¨ Ùˆ Ø±ÙˆØ§ÛŒØª Ø±ÙˆØ§Ù† Ø§Ø² Ù†Ù‚Ø§Ø· Ù‚ÙˆØª Ø¢Ù† Ø§Ø³Øª. ÙÙ‚Ø· Ø¨Ø±Ø®ÛŒ Ù„Ø­Ø¸Ø§Øª Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù†Ø¯ Ø¨Ø§Ø´Ù†Ø¯.",
    ]
}

FALLBACK_MOVIE = {
    'title': 'Inception',
    'year': '2010',
    'plot': 'Ø¯Ø²Ø¯ÛŒ Ú©Ù‡ Ø§Ø³Ø±Ø§Ø± Ø´Ø±Ú©Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ ÙÙ†Ø§ÙˆØ±ÛŒ Ø±ÙˆÛŒØ§ Ù…ÛŒâ€ŒØ¯Ø²Ø¯Ø¯ØŒ Ø¨Ø§ÛŒØ¯ Ø§ÛŒØ¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± Ø°Ù‡Ù† ÛŒÚ© Ù…Ø¯ÛŒØ± Ø¨Ú©Ø§Ø±Ø¯. Ú¯Ø°Ø´ØªÙ‡ ØºÙ…â€ŒØ§Ù†Ú¯ÛŒØ² Ø§Ùˆ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù¾Ø±ÙˆÚ˜Ù‡ Ø±Ø§ Ø¨Ù‡ ÙØ§Ø¬Ø¹Ù‡ Ø¨Ú©Ø´Ø§Ù†Ø¯.',
    'imdb': '8.8/10',
    'trailer': 'https://www.youtube.com/watch?v=YoHD9XEInc0',
    'poster': 'https://m.media-amazon.com/images/M/MV5BMjAxMzY3NjcxNF5BMl5BanBnXkFtZTcwNTI5OTM0Mw@@._V1_SX300.jpg',
    'comment': 'Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø§Ø«Ø±ÛŒ Ø¬Ø°Ø§Ø¨ Ø¯Ø± Ú˜Ø§Ù†Ø± Ø¹Ù„Ù…ÛŒ_ØªØ®ÛŒÙ„ÛŒ Ø§Ø³Øª Ú©Ù‡ Ø¨Ø§ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ùˆ Ø¬Ù„ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ø®ÛŒØ±Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ØŒ Ø°Ù‡Ù† Ø±Ø§ Ø¨Ù‡ Ú†Ø§Ù„Ø´ Ù…ÛŒâ€ŒÚ©Ø´Ø¯. Ø¨Ø§Ø²ÛŒÚ¯Ø±ÛŒ Ùˆ Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ø¨ÛŒâ€ŒÙ†Ù‚ØµØŒ Ø¢Ù† Ø±Ø§ ÙØ±Ø§Ù…ÙˆØ´â€ŒÙ†Ø´Ø¯Ù†ÛŒ Ú©Ø±Ø¯Ù‡â€ŒØ§Ù†Ø¯. ØªÙ†Ù‡Ø§ Ø¶Ø¹ÙØŒ Ø±ÛŒØªÙ… Ú©Ù†Ø¯ Ø¨Ø±Ø®ÛŒ ØµØ­Ù†Ù‡â€ŒÙ‡Ø§Ø³Øª.',
    'rating': 4,
    'special': True,
    'genres': ['Ø¹Ù„Ù…ÛŒ_ØªØ®ÛŒÙ„ÛŒ', 'Ù‡ÛŒØ¬Ø§Ù†_Ø§Ù†Ú¯ÛŒØ²']
}

# --- Ø´Ù…Ø§Ø±Ø´Ú¯Ø± Ø®Ø·Ø§Ù‡Ø§ÛŒ API ---
api_errors = {
    'rapidapi': 0,
    'tmdb': 0,
    'omdb': 0
}

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
def clean_text(text):
    if not text or text == 'N/A':
        return None
    return text[:300]

def shorten_plot(text, max_sentences=3):
    sentences = [s.strip() for s in text.split('. ') if s.strip() and s.strip()[-1] in '.!ØŸ']
    return '. '.join(sentences[:max_sentences]) + ('.' if sentences else '')

def is_farsi(text):
    farsi_chars = r'[\u0600-\u06FF]'
    return bool(re.search(farsi_chars, text))

def is_valid_plot(text):
    if not text or len(text.split()) < 5:
        return False
    sentences = text.split('. ')
    return len([s for s in sentences if s.strip() and s.strip()[-1] in '.!ØŸ']) >= 1

def get_fallback_by_genre(options, genres):
    for genre in genres:
        if genre in options:
            available = [opt for opt in options[genre] if opt not in previous_comments]
            if available:
                return random.choice(available)
    available = [opt for genre in options for opt in options[genre] if opt not in previous_comments]
    return random.choice(available) if available else options['Ø³Ø§ÛŒØ±'][0]

async def make_api_request(url, headers=None, retries=5, timeout=15):
    for attempt in range(retries):
        try:
            async with aiohttp.ClientSession(timeout=ClientTimeout(total=timeout)) as session:
                async with session.get(url, headers=headers) as response:
                    if response.status == 429:
                        logger.warning(f"Ø®Ø·Ø§ÛŒ 429: Rate LimitØŒ ØªÙ„Ø§Ø´ {attempt + 1}")
                        await asyncio.sleep(3)
                        continue
                    if response.status == 401:
                        logger.error(f"Ø®Ø·Ø§ÛŒ 401: Ú©Ù„ÛŒØ¯ API Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
                        return None
                    if response.status != 200:
                        logger.error(f"Ø®Ø·Ø§ÛŒ {response.status}: {await response.text()}")
                        return None
                    data = await response.json()
                    return data
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(3)
        except aiohttp.ClientResponseError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ù¾Ø§Ø³Ø® (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(3)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª API (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(3)
    return None

async def get_imdb_score_rapidapi(title):
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ù…ØªÛŒØ§Ø² RapidAPI Ø¨Ø±Ø§ÛŒ: {title}")
    headers = {
        "x-rapidapi-key": RAPIDAPI_KEY,
        "x-rapidapi-host": "imdb236.p.rapidapi.com"
    }
    encoded_title = urllib.parse.quote(title)
    url = f"https://imdb236.p.rapidapi.com/v1/SearchMovie/{encoded_title}"
    data = await make_api_request(url, headers=headers)
    if not data or not data.get('results'):
        logger.warning(f"RapidAPI Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯")
        api_errors['rapidapi'] += 1
        return None
    movie = data['results'][0]
    imdb_score = movie.get('imDbRating', '0')
    if float(imdb_score) < 6.0:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯")
        return None
    api_errors['rapidapi'] = 0  # Ø±ÛŒØ³Øª Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± ØµÙˆØ±Øª Ù…ÙˆÙÙ‚ÛŒØª
    return f"{float(imdb_score):.1f}/10"

async def get_imdb_score_tmdb(title):
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª TMDB Ø¨Ø±Ø§ÛŒ: {title}")
    encoded_title = urllib.parse.quote(title)
    url = f"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={encoded_title}&language=en-US"
    data = await make_api_request(url)
    if not data or not data.get('results'):
        logger.warning(f"TMDB Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯")
        api_errors['tmdb'] += 1
        return None
    movie = data['results'][0]
    imdb_score = movie.get('vote_average', 0)
    if imdb_score < 6.0:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯")
        return None
    api_errors['tmdb'] = 0
    return f"{float(imdb_score):.1f}/10"

async def get_imdb_score_omdb(title):
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª OMDb Ø¨Ø±Ø§ÛŒ: {title}")
    encoded_title = urllib.parse.quote(title)
    url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={encoded_title}&type=movie"
    data = await make_api_request(url)
    if not data or data.get('Response') == 'False':
        logger.warning(f"OMDb Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯: {data.get('Error')}")
        api_errors['omdb'] += 1
        return None
    imdb_score = data.get('imdbRating', '0')
    if float(imdb_score) < 6.0:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯")
        return None
    api_errors['omdb'] = 0
    return f"{float(imdb_score):.1f}/10"

async def check_poster(url):
    try:
        async with aiohttp.ClientSession(timeout=ClientTimeout(total=5)) as session:
            async with session.head(url) as response:
                if response.status != 200:
                    return False
                content_length = response.headers.get('Content-Length')
                if content_length and int(content_length) > 5 * 1024 * 1024:  # 5MB
                    logger.warning(f"Ù¾ÙˆØ³ØªØ± {url} Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª")
                    return False
                return True
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ú†Ú© Ù¾ÙˆØ³ØªØ± {url}: {str(e)}")
        return False

async def save_cache_to_file():
    try:
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cached_movies, f, ensure_ascii=False)
        logger.info("Ú©Ø´ Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´ Ø¨Ù‡ ÙØ§ÛŒÙ„: {str(e)}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø´: {str(e)}")

async def load_cache_from_file():
    global cached_movies
    try:
        if os.path.exists(CACHE_FILE):
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                cached_movies = json.load(f)
            logger.info(f"Ú©Ø´ Ø§Ø² ÙØ§ÛŒÙ„ Ù„ÙˆØ¯ Ø´Ø¯: {len(cached_movies)} ÙÛŒÙ„Ù…")
            return True
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ú©Ø´ Ø§Ø² ÙØ§ÛŒÙ„: {str(e)}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ Ú©Ø´: {str(e)}")
        return False

async def save_posted_movies_to_file():
    try:
        with open(POSTED_MOVIES_FILE, 'w', encoding='utf-8') as f:
            json.dump(posted_movies, f, ensure_ascii=False)
        logger.info("Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {str(e)}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {str(e)}")

async def load_posted_movies_from_file():
    global posted_movies
    try:
        if os.path.exists(POSTED_MOVIES_FILE):
            with open(POSTED_MOVIES_FILE, 'r', encoding='utf-8') as f:
                posted_movies = json.load(f)
            logger.info(f"Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡ Ù„ÙˆØ¯ Ø´Ø¯: {len(posted_movies)} ÙÛŒÙ„Ù…")
            return True
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {str(e)}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„ÙˆØ¯ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {str(e)}")
        return False

async def get_movie_info(title):
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ù…: {title}")
    
    # 1. RapidAPI
    logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ RapidAPI Ø¨Ø±Ø§ÛŒ {title}")
    rapidapi_score = await get_imdb_score_rapidapi(title)
    if rapidapi_score:
        headers = {
            "x-rapidapi-key": RAPIDAPI_KEY,
            "x-rapidapi-host": "imdb236.p.rapidapi.com"
        }
        encoded_title = urllib.parse.quote(title)
        rapidapi_url = f"https://imdb236.p.rapidapi.com/v1/SearchMovie/{encoded_title}"
        rapidapi_data = await make_api_request(rapidapi_url, headers=headers)
        if rapidapi_data and rapidapi_data.get('results'):
            movie = rapidapi_data['results'][0]
            genres = movie.get('genres', '').split(', ')
            genres = [GENRE_TRANSLATIONS.get(g, 'Ø³Ø§ÛŒØ±') for g in genres]
            return {
                'title': movie.get('title', title),
                'year': movie.get('description', '')[:4],
                'plot': get_fallback_by_genre(FALLBACK_PLOTS, genres),
                'imdb': rapidapi_score,
                'trailer': None,
                'poster': movie.get('image', None),
                'genres': genres[:3]
            }
    
    # 2. TMDB
    logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ TMDB Ø¨Ø±Ø§ÛŒ {title}")
    encoded_title = urllib.parse.quote(title)
    search_url_en = f"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={encoded_title}&language=en-US"
    tmdb_data_en = await make_api_request(search_url_en)
    if tmdb_data_en and tmdb_data_en.get('results'):
        movie = tmdb_data_en['results'][0]
        movie_id = movie.get('id')
        tmdb_title = movie.get('title', title)
        tmdb_poster = f"https://image.tmdb.org/t/p/w500{movie.get('poster_path')}" if movie.get('poster_path') else None
        
        details_url = f"https://api.themoviedb.org/3/movie/{movie_id}?api_key={TMDB_API_KEY}&language=en-US"
        details_data = await make_api_request(details_url)
        genres = [GENRE_TRANSLATIONS.get(g['name'], 'Ø³Ø§ÛŒØ±') for g in details_data.get('genres', [])]
        
        search_url_fa = f"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={encoded_title}&language=fa-IR"
        tmdb_data_fa = await make_api_request(search_url_fa)
        tmdb_plot = tmdb_data_fa['results'][0].get('overview', '') if tmdb_data_fa.get('results') else ''
        tmdb_year = tmdb_data_fa['results'][0].get('release_date', 'N/A')[:4] if tmdb_data_fa.get('results') else 'N/A'
        
        trailer = None
        videos_url = f"https://api.themoviedb.org/3/movie/{movie_id}/videos?api_key={TMDB_API_KEY}&language=en"
        videos_data = await make_api_request(videos_url)
        if videos_data and videos_data.get('results'):
            for video in videos_data['results']:
                if video['type'] == 'Trailer' and video['site'] == 'YouTube':
                    trailer = f"https://www.youtube.com/watch?v={video['key']}"
                    break
        
        imdb_score = await get_imdb_score_tmdb(tmdb_title)
        if not imdb_score:
            logger.warning(f"Ø§Ù…ØªÛŒØ§Ø² Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {tmdb_title} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        else:
            plot = shorten_plot(tmdb_plot) if tmdb_plot and is_farsi(tmdb_plot) else get_fallback_by_genre(FALLBACK_PLOTS, genres)
            previous_plots.append(plot)
            if len(previous_plots) > 10:
                previous_plots.pop(0)
            return {
                'title': tmdb_title,
                'year': tmdb_year,
                'plot': plot,
                'imdb': imdb_score,
                'trailer': trailer,
                'poster': tmdb_poster,
                'genres': genres[:3]
            }
    
    # 3. OMDb
    logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ OMDb Ø¨Ø±Ø§ÛŒ {title}")
    omdb_url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={encoded_title}&type=movie"
    omdb_data = await make_api_request(omdb_url)
    if omdb_data and omdb_data.get('Response') == 'True':
        imdb_score = omdb_data.get('imdbRating', '0')
        if float(imdb_score) >= 6.0:
            genres = omdb_data.get('Genre', '').split(', ')
            genres = [GENRE_TRANSLATIONS.get(g.strip(), 'Ø³Ø§ÛŒØ±') for g in genres]
            return {
                'title': omdb_data.get('Title', title),
                'year': omdb_data.get('Year', 'N/A'),
                'plot': omdb_data.get('Plot', get_fallback_by_genre(FALLBACK_PLOTS, genres)),
                'imdb': f"{float(imdb_score):.1f}/10",
                'trailer': None,
                'poster': omdb_data.get('Poster', None),
                'genres': genres[:3]
            }
    
    logger.error(f"Ù‡ÛŒÚ† API Ø¨Ø±Ø§ÛŒ {title} Ø¬ÙˆØ§Ø¨ Ù†Ø¯Ø§Ø¯")
    if api_errors['rapidapi'] > 5 or api_errors['tmdb'] > 5 or api_errors['omdb'] > 5:
        await send_admin_alert(None, f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: APIÙ‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯ ({api_errors}) Ø®Ø·Ø§ Ø¯Ø§Ø±Ù†Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
    return FALLBACK_MOVIE

async def generate_comment(genres):
    global gemini_available, openai_available
    logger.info("ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„...")
    
    if gemini_available:
        max_attempts = 2
        for attempt in range(max_attempts):
            try:
                model = genai.GenerativeModel('gemini-1.5-flash')
                prompt = "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¯Ø± 3 Ø¬Ù…Ù„Ù‡ Ú©Ø§Ù…Ù„ (Ù‡Ø± Ø¬Ù…Ù„Ù‡ Ø¨Ø§ Ù†Ù‚Ø·Ù‡ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§Ø¨Ø¯). Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯."
                response = await model.generate_content_async(prompt)
                text = response.text.strip()
                sentences = [s.strip() for s in text.split('. ') if s.strip() and s.strip()[-1] in '.!ØŸ']
                if len(sentences) >= 3 and is_farsi(text) and len(text.split()) > 15:
                    previous_comments.append(text)
                    if len(previous_comments) > 10:
                        previous_comments.pop(0)
                    return '. '.join(sentences[:3]) + '.'
                logger.warning(f"ØªØ­Ù„ÛŒÙ„ Gemini Ù†Ø§Ù…Ø¹ØªØ¨Ø± (ØªÙ„Ø§Ø´ {attempt + 1}): {text}")
            except google_exceptions.ResourceExhausted as e:
                logger.error(f"Ø®Ø·Ø§: ØªÙˆÚ©Ù† Gemini ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª: {str(e)}")
                gemini_available = False
                await send_admin_alert(None, "âŒ ØªÙˆÚ©Ù† Gemini ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª. ØªÙ„Ø§Ø´ Ø¨Ø§ Open AI...")
            except google_exceptions.ClientError as e:
                logger.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª Gemini (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Gemini API (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
    
    if openai_available:
        for attempt in range(5):
            try:
                response = await client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¯Ø± 3 Ø¬Ù…Ù„Ù‡ Ú©Ø§Ù…Ù„ (Ù‡Ø± Ø¬Ù…Ù„Ù‡ Ø¨Ø§ Ù†Ù‚Ø·Ù‡ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§Ø¨Ø¯). Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    max_tokens=150,
                    temperature=0.7,
                    timeout=30
                )
                text = response.choices[0].message.content.strip()
                sentences = [s.strip() for s in text.split('. ') if s.strip() and s.strip()[-1] in '.!ØŸ']
                if len(sentences) >= 3 and is_farsi(text) and len(text.split()) > 15:
                    previous_comments.append(text)
                    if len(previous_comments) > 10:
                        previous_comments.pop(0)
                    return '. '.join(sentences[:3]) + '.'
                logger.warning(f"ØªØ­Ù„ÛŒÙ„ Open AI Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {text}")
            except aiohttp.client_exceptions.ClientConnectorError as e:
                logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Open AI (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
                if attempt == 4:
                    openai_available = False
                    await send_admin_alert(None, "âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Open AI. Ù‡ÛŒÚ† ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.")
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Open AI API (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
                if attempt == 4:
                    openai_available = False
                    await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Open AI: {str(e)}")
            await asyncio.sleep(3)
    
    logger.warning("Ù‡ÛŒÚ† ØªØ­Ù„ÛŒÙ„Ú¯Ø±ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
    comment = get_fallback_by_genre(FALLBACK_COMMENTS, genres)
    previous_comments.append(comment)
    if len(previous_comments) > 10:
        previous_comments.pop(0)
    return comment

async def send_admin_alert(context: ContextTypes.DEFAULT_TYPE, message: str):
    try:
        async with aiohttp.ClientSession() as session:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
            payload = {"chat_id": ADMIN_ID, "text": message}
            async with session.post(url, json=payload) as response:
                result = await response.json()
                if not result.get('ok'):
                    logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†: {result}")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†: {str(e)}")

async def fetch_movies_to_cache():
    global cached_movies, last_fetch_time
    logger.info("Ø´Ø±ÙˆØ¹ Ø¢Ù¾Ø¯ÛŒØª Ú©Ø´ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§...")
    new_movies = []
    for attempt in range(3):
        try:
            async with aiohttp.ClientSession(timeout=ClientTimeout(total=10)) as session:
                page = 1
                while len(new_movies) < 100 and page <= 5:
                    # 1. RapidAPI
                    logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ RapidAPI Ø¨Ø±Ø§ÛŒ Ú©Ø´ØŒ ØµÙØ­Ù‡ {page}")
                    headers = {
                        "x-rapidapi-key": RAPIDAPI_KEY,
                        "x-rapidapi-host": "imdb236.p.rapidapi.com"
                    }
                    rapidapi_url = f"https://imdb236.p.rapidapi.com/v1/MostPopularMovies"
                    rapidapi_data = await make_api_request(rapidapi_url, headers=headers)
                    if rapidapi_data and rapidapi_data.get('items'):
                        for m in rapidapi_data['items']:
                            if float(m.get('imDbRating', 0)) >= 6.0:
                                new_movies.append({'title': m['title'], 'id': m['id']})
                        break
                    
                    # 2. TMDB
                    logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ TMDB Ø¨Ø±Ø§ÛŒ Ú©Ø´ØŒ ØµÙØ­Ù‡ {page}")
                    tmdb_url = f"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=en-US&page={page}"
                    tmdb_data = await make_api_request(tmdb_url)
                    if tmdb_data and tmdb_data.get('results'):
                        for m in tmdb_data['results']:
                            if (m.get('title') and m.get('id') and
                                m.get('original_language') != 'hi' and
                                'IN' not in m.get('origin_country', []) and
                                m.get('poster_path')):
                                imdb_score = await get_imdb_score_omdb(m['title']) or await get_imdb_score_tmdb(m['title'])
                                if imdb_score and float(imdb_score.split('/')[0]) >= 6.0:
                                    new_movies.append({'title': m['title'], 'id': m['id']})
                        page += 1

                    # 3. OMDb
                    logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ OMDb Ø¨Ø±Ø§ÛŒ Ú©Ø´ØŒ ØµÙØ­Ù‡ {page}")
                    omdb_url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&s=movie&type=movie&page={page}"
                    omdb_data = await make_api_request(omdb_url)
                    if omdb_data and omdb_data.get('Search'):
                        for m in omdb_data['Search']:
                            imdb_score = await get_imdb_score_omdb(m['Title'])
                            if imdb_score and float(imdb_score.split('/')[0]) >= 6.0:
                                new_movies.append({'title': m['Title'], 'id': m['imdbID']})
                        page += 1
                
                if new_movies:
                    cached_movies = new_movies[:100]
                    last_fetch_time = datetime.now()
                    await save_cache_to_file()
                    logger.info(f"Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯. ØªØ¹Ø¯Ø§Ø¯: {len(cached_movies)}")
                    return True
                logger.error("Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù‡ÛŒÚ† API Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ø¯ÛŒØª Ú©Ø´ (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
            await asyncio.sleep(3)
    
    logger.error("ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¢Ù¾Ø¯ÛŒØª Ú©Ø´ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯ØŒ Ù„ÙˆØ¯ Ø§Ø² ÙØ§ÛŒÙ„")
    if await load_cache_from_file():
        return True
    cached_movies = [{'title': 'Inception', 'id': 'tt1375666'}, {'title': 'The Matrix', 'id': 'tt0133093'}]
    await save_cache_to_file()
    last_fetch_time = datetime.now()
    await send_admin_alert(None, "âŒ Ø®Ø·Ø§: Ú©Ø´ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ Ø¢Ù¾Ø¯ÛŒØª Ù†Ø´Ø¯ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
    return False

async def auto_fetch_movies(context: ContextTypes.DEFAULT_TYPE):
    logger.info("Ø´Ø±ÙˆØ¹ Ø¢Ù¾Ø¯ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ø´...")
    if await fetch_movies_to_cache():
        logger.info("Ø¢Ù¾Ø¯ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ø´ Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
    else:
        logger.error("Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ø¯ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ø´")
        await send_admin_alert(context, "âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ø¯ÛŒØª Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ø´")

async def get_random_movie(max_retries=3):
    logger.info("Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÙ„Ù… ØªØµØ§Ø¯ÙÛŒ...")
    for attempt in range(max_retries):
        try:
            if not cached_movies or (datetime.now() - last_fetch_time).seconds > FETCH_INTERVAL:
                logger.info("Ú©Ø´ Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù‚Ø¯ÛŒÙ…ÛŒØŒ Ø¢Ù¾Ø¯ÛŒØª Ú©Ø´...")
                await fetch_movies_to_cache()
            
            if not cached_movies:
                logger.error("Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø¯Ø± Ú©Ø´ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
                return FALLBACK_MOVIE
            
            available_movies = [m for m in cached_movies if m['id'] not in posted_movies]
            if not available_movies:
                logger.warning("Ù‡ÛŒÚ† ÙÛŒÙ„Ù… Ø¬Ø¯ÛŒØ¯ÛŒ Ø¯Ø± Ú©Ø´ Ù†ÛŒØ³ØªØŒ Ø±ÛŒØ³Øª Ù„ÛŒØ³Øª Ù¾Ø³Øªâ€ŒØ´Ø¯Ù‡â€ŒÙ‡Ø§")
                posted_movies.clear()
                await save_posted_movies_to_file()
                available_movies = cached_movies
            
            movie = random.choice(available_movies)
            logger.info(f"ÙÛŒÙ„Ù… Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {movie['title']} (ØªÙ„Ø§Ø´ {attempt + 1})")
            movie_info = await get_movie_info(movie['title'])
            if not movie_info or movie_info['imdb'] == '0.0/10':
                logger.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÛŒÙ„Ù… {movie['title']} Ù†Ø§Ù…Ø¹ØªØ¨Ø±ØŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
                continue
            
            posted_movies.append(movie['id'])
            await save_posted_movies_to_file()
            comment = await generate_comment(movie_info['genres'])
            if not comment:
                logger.error("ØªØ­Ù„ÛŒÙ„ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
                comment = get_fallback_by_genre(FALLBACK_COMMENTS, movie_info['genres'])
            
            imdb_score = float(movie_info['imdb'].split('/')[0])
            logger.info(f"Ø§Ù…ØªÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ {movie['title']}: {imdb_score}")
            if imdb_score >= 8.5:
                rating = 5
            elif 7.5 <= imdb_score < 8.5:
                rating = 4
            elif 6.5 <= imdb_score < 7.5:
                rating = 3
            elif 6.0 <= imdb_score < 6.5:
                rating = 2
            else:
                rating = 1
            
            if movie_info['poster']:
                if not await check_poster(movie_info['poster']):
                    movie_info['poster'] = None
            
            return {
                **movie_info,
                'comment': comment,
                'rating': rating,
                'special': imdb_score >= 8.5
            }
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÙ„Ù… (ØªÙ„Ø§Ø´ {attempt + 1}): {str(e)}")
            if attempt == max_retries - 1:
                logger.error("ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ ØªÙ…Ø§Ù… Ø´Ø¯ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
                return FALLBACK_MOVIE
    logger.error("ØªÙ„Ø§Ø´â€ŒÙ‡Ø§ ØªÙ…Ø§Ù… Ø´Ø¯ØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
    return FALLBACK_MOVIE

def format_movie_post(movie):
    stars = 'â­ï¸' * movie['rating']
    special = ' ğŸ‘‘' if movie['special'] else ''
    channel_link = 'https://t.me/bestwatch_channel'
    rlm = '\u200F'
    genres = ' '.join([f"#{g.replace(' ', '_')}" for g in movie['genres']]) if movie['genres'] else '#Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ'
    
    post_sections = [
        f"""
ğŸ¬ <b>Ø¹Ù†ÙˆØ§Ù† ÙÛŒÙ„Ù…:</b>
<b>{clean_text(movie['title']) or 'Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†'}{special}</b>

ğŸ“… <b>Ø³Ø§Ù„ ØªÙˆÙ„ÛŒØ¯: {clean_text(movie['year']) or 'Ù†Ø§Ù…Ø´Ø®Øµ'}</b>
"""
    ]
    
    if movie['plot'] and clean_text(movie['plot']) != 'Ù…ØªÙ† Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª':
        post_sections.append(f"""
ğŸ“ <b>Ø®Ù„Ø§ØµÙ‡ Ø¯Ø§Ø³ØªØ§Ù†:</b>
{rlm}{clean_text(movie['plot'])}
""")
    
    post_sections.append(f"""
ğŸŒŸ <b>Ø§Ù…ØªÛŒØ§Ø² IMDB:</b>
<b>{clean_text(movie['imdb']) or 'Ù†Ø§Ù…Ø´Ø®Øµ'}</b>
""")
    
    if movie['trailer'] and movie['trailer'].startswith('http'):
        post_sections.append(f"""
ğŸ <b>Ù„ÛŒÙ†Ú© ØªØ±ÛŒÙ„Ø±:</b>
{clean_text(movie['trailer'])}
""")
    
    if movie['comment']:
        post_sections.append(f"""
ğŸ¿ <b>Ø­Ø±Ù Ù…Ø§:</b>
{rlm}{clean_text(movie['comment'])}
""")
    
    post_sections.append(f"""
ğŸ¯ <b>Ø§Ø±Ø²Ø´ Ø¯ÛŒØ¯Ù†: {stars}</b>

{genres}

{channel_link}
""")
    
    return ''.join(post_sections)

def get_main_menu():
    toggle_text = "ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø±Ø¨Ø§Øª" if bot_enabled else "ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ø±Ø¨Ø§Øª"
    keyboard = [
        [
            InlineKeyboardButton("Ø¢Ù¾Ø¯ÛŒØª Ù„ÛŒØ³Øª", callback_data='fetch_movies'),
            InlineKeyboardButton("Ø§Ø±Ø³Ø§Ù„ ÙÙˆØ±ÛŒ", callback_data='post_now')
        ],
        [
            InlineKeyboardButton("ØªØ³Øªâ€ŒÙ‡Ø§", callback_data='tests_menu'),
            InlineKeyboardButton("Ø¢Ù…Ø§Ø± Ø¨Ø§Ø²Ø¯ÛŒØ¯", callback_data='stats')
        ],
        [
            InlineKeyboardButton(toggle_text, callback_data='toggle_bot'),
            InlineKeyboardButton("Ø±ÛŒØ³Øª Webhook", callback_data='reset_webhook')
        ]
    ]
    return InlineKeyboardMarkup(keyboard)

def get_tests_menu():
    keyboard = [
        [
            InlineKeyboardButton("Ø¯Ø³ØªØ±Ø³ÛŒ ÙÙ†ÛŒ", callback_data='test_all'),
            InlineKeyboardButton("Ø¯Ø³ØªØ±Ø³ÛŒ Ú©Ø§Ù†Ø§Ù„", callback_data='test_channel')
        ],
        [
            InlineKeyboardButton("Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data='back_to_main')
        ]
    ]
    return InlineKeyboardMarkup(keyboard)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if str(update.message.from_user.id) != ADMIN_ID:
        logger.info(f"Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø² ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø±: {update.message.from_user.id}")
        return
    logger.info("Ø¯Ø³ØªÙˆØ± /start Ø§Ø¬Ø±Ø§ Ø´Ø¯")
    await update.message.reply_text("ğŸ¤– Ù…Ù†ÙˆÛŒ Ø§Ø¯Ù…ÛŒÙ†", reply_markup=get_main_menu())

async def debug(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if str(update.message.from_user.id) != ADMIN_ID:
        logger.info(f"Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ debug: {update.message.from_user.id}")
        return
    logger.info("Ø§Ø¬Ø±Ø§ÛŒ debug")
    try:
        update_dict = update.to_dict()
        callback_query = update.callback_query
        callback_data = callback_query.data if callback_query else "Ù‡ÛŒÚ† callback_query"
        await update.message.reply_text(
            f"Ø³Ø§Ø®ØªØ§Ø± Ø¢Ù¾Ø¯ÛŒØª:\n{update_dict}\n\nCallbackQuery: {callback_query}\nCallbackData: {callback_data}"
        )
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯ÛŒØ¨Ø§Ú¯: {str(e)}")
        await update.message.reply_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯ÛŒØ¨Ø§Ú¯: {str(e)}")

async def back_to_main(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ back_to_main")
    await query.answer()
    try:
        await query.message.edit_text("ğŸ¤– Ù…Ù†ÙˆÛŒ Ø§Ø¯Ù…ÛŒÙ†", reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± back_to_main: {str(e)}")
        await query.message.edit_text(f"âŒ Ø®Ø·Ø§: {str(e)}", reply_markup=get_main_menu())

async def tests_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ tests_menu")
    await query.answer()
    try:
        await query.message.edit_text("ğŸ›  Ù…Ù†ÙˆÛŒ ØªØ³Øªâ€ŒÙ‡Ø§", reply_markup=get_tests_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± tests_menu: {str(e)}")
        await query.message.edit_text(f"âŒ Ø®Ø·Ø§: {str(e)}", reply_markup=get_main_menu())

async def fetch_movies_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ fetch_movies")
    await query.answer()
    msg = await query.message.edit_text("Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù¾Ø¯ÛŒØª Ù„ÛŒØ³Øª...")
    try:
        if await fetch_movies_to_cache():
            keyboard = [
                [
                    InlineKeyboardButton("Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§", callback_data='show_movies'),
                    InlineKeyboardButton("Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data='back_to_main')
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            await msg.edit_text(f"âœ… Ù„ÛŒØ³Øª Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯! ({len(cached_movies)} ÙÛŒÙ„Ù…)", reply_markup=reply_markup)
        else:
            await msg.edit_text("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù¾Ø¯ÛŒØª Ù„ÛŒØ³Øª", reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± fetch_movies: {str(e)}")
        await msg.edit_text(f"âŒ Ø®Ø·Ø§: {str(e)}", reply_markup=get_main_menu())

async def post_now_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ post_now")
    await query.answer()
    msg = await query.message.edit_text("Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø³Øª...")
    try:
        if not bot_enabled:
            logger.error("Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ú©Ù†Ø³Ù„ Ø´Ø¯: Ø±Ø¨Ø§Øª ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª")
            await msg.edit_text("âŒ Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ú©Ù†Ø³Ù„ Ø´Ø¯: Ø±Ø¨Ø§Øª ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª", reply_markup=get_main_menu())
            return
        movie = await get_random_movie()
        if not movie:
            logger.error("Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯")
            await msg.edit_text("âŒ Ø®Ø·Ø§ Ø¯Ø± ÛŒØ§ÙØªÙ† ÙÛŒÙ„Ù…", reply_markup=get_main_menu())
            return
        
        logger.info(f"Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¨Ø±Ø§ÛŒ: {movie['title']}")
        if movie['poster']:
            await context.bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=movie['poster'],
                caption=format_movie_post(movie),
                parse_mode='HTML',
                disable_notification=True
            )
        else:
            await context.bot.send_message(
                chat_id=CHANNEL_ID,
                text=format_movie_post(movie),
                parse_mode='HTML',
                disable_notification=True
            )
        await msg.edit_text(f"âœ… Ù¾Ø³Øª {movie['title']} Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯", reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± post_now: {e}")
        await msg.edit_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª: {str(e)}", reply_markup=get_main_menu())

async def run_tests(context: ContextTypes.DEFAULT_TYPE):
    results = []
    
    # ØªØ³Øª RapidAPI
    headers = {
        "x-rapidapi-key": RAPIDAPI_KEY,
        "x-rapidapi-host": "imdb236.p.rapidapi.com"
    }
    url = f"https://imdb236.p.rapidapi.com/v1/SearchMovie/test"
    data = await make_api_request(url, headers=headers)
    rapidapi_status = "âœ… RapidAPI Ø§ÙˆÚ©ÛŒ" if data and (data.get('results') or data.get('errorMessage')) else f"âŒ RapidAPI Ø®Ø·Ø§: {data}"
    results.append(rapidapi_status)

    # ØªØ³Øª TMDB
    tmdb_url = f"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=fa-IR&page=1"
    tmdb_data = await make_api_request(tmdb_url)
    tmdb_status = "âœ… TMDB Ø§ÙˆÚ©ÛŒ" if tmdb_data and tmdb_data.get('results') else f"âŒ TMDB Ø®Ø·Ø§: {tmdb_data}"
    results.append(tmdb_status)

    # ØªØ³Øª OMDb
    omdb_url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t=Inception&type=movie"
    omdb_data = await make_api_request(omdb_url)
    omdb_status = "âœ… OMDb Ø§ÙˆÚ©ÛŒ" if omdb_data and omdb_data.get('Response') == 'True' else f"âŒ OMDb Ø®Ø·Ø§: {omdb_data.get('Error')}"
    results.append(omdb_status)

    # ØªØ³Øª JobQueue
    job_queue = context.job_queue
    results.append("âœ… JobQueue ÙØ¹Ø§Ù„" if job_queue else "âŒ JobQueue ØºÛŒØ±ÙØ¹Ø§Ù„")

    # ØªØ³Øª Gemini
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt = "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."
        response = await model.generate_content_async(prompt)
        text = response.text.strip()
        gemini_status = "âœ… Gemini Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else "âŒ Gemini Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
        results.append(gemini_status)
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Gemini: {str(e)}")
        results.append(f"âŒ Gemini Ø®Ø·Ø§: {str(e)}")

    # ØªØ³Øª Open AI
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Write in Persian."},
                {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
            ],
            max_tokens=50,
            temperature=0.7,
            timeout=30
        )
        text = response.choices[0].message.content.strip()
        openai_status = "âœ… Open AI Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else "âŒ Open AI Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
        results.append(openai_status)
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Open AI: {str(e)}")
        results.append(f"âŒ Open AI Ø®Ø·Ø§: {str(e)}")
    
    await send_admin_alert(context, "ğŸ“‹ Ù†ØªØ§ÛŒØ¬ ØªØ³Øª:\n" + "\n".join(results))

async def test_all_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ test_all")
    await query.answer()
    msg = await query.message.edit_text("Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§... Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡â€ŒØ²ÙˆØ¯ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
    asyncio.create_task(run_tests(context))
    await msg.edit_text("âœ… ØªØ³Øªâ€ŒÙ‡Ø§ Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù†Ø¯. Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ† Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.", reply_markup=get_tests_menu())

async def test_channel_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ test_channel")
    await query.answer()
    msg = await query.message.edit_text("Ø¯Ø± Ø­Ø§Ù„ ØªØ³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„...")
    try:
        async with aiohttp.ClientSession() as session:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/getChatMember?chat_id={CHANNEL_ID}&user_id={context.bot.id}"
            async with session.get(url) as response:
                data = await response.json()
                if not data.get('ok'):
                    raise Exception(f"Ø®Ø·Ø§ Ø¯Ø± API ØªÙ„Ú¯Ø±Ø§Ù…: {data.get('description')}")
                if data['result']['status'] not in ['administrator', 'creator']:
                    raise Exception("Ø¨Ø§Øª Ø§Ø¯Ù…ÛŒÙ† Ú©Ø§Ù†Ø§Ù„ Ù†ÛŒØ³Øª.")
        await msg.edit_text("âœ… Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„ Ø§ÙˆÚ©ÛŒ", reply_markup=get_tests_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„: {str(e)}")
        await msg.edit_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„: {str(e)}", reply_markup=get_tests_menu())

async def stats_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ stats")
    await query.answer()
    msg = await query.message.edit_text("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ú©Ø§Ù†Ø§Ù„...")
    
    try:
        async with aiohttp.ClientSession() as session:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/getChatMember?chat_id={CHANNEL_ID}&user_id={context.bot.id}"
            async with session.get(url) as response:
                data = await response.json()
                if not data.get('ok') or data['result']['status'] not in ['administrator', 'creator']:
                    raise Exception("Ø¨Ø§Øª Ø§Ø¯Ù…ÛŒÙ† Ú©Ø§Ù†Ø§Ù„ Ù†ÛŒØ³Øª.")
        
        now = datetime.now()
        views_week = []
        posts_count = 0
        
        async with aiohttp.ClientSession() as session:
            url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/getUpdates?offset=-100"
            async with session.get(url) as response:
                data = await response.json()
                if not data.get('ok') or not data.get('result'):
                    raise Exception("Ù‡ÛŒÚ† Ù¾ÛŒØ§Ù…ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù¾Ø³Øª Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ Ù…Ù†ØªØ´Ø± Ú©Ù†ÛŒØ¯.")
                
                for update in data['result']:
                    if 'channel_post' in update:
                        post = update['channel_post']
                        if post.get('chat', {}).get('id') != int(CHANNEL_ID.replace('@', '')):
                            continue
                        if not post.get('views'):
                            continue
                        message_time = datetime.fromtimestamp(post['date'])
                        time_diff = now - message_time
                        if time_diff <= timedelta(days=7):
                            views_week.append(post['views'])
                            posts_count += 1
        
        if not views_week:
            raise Exception("Ù‡ÛŒÚ† Ù¾Ø³ØªÛŒ Ø¯Ø± 7 Ø±ÙˆØ² Ø§Ø®ÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ù¾Ø³Øª Ù…Ù†ØªØ´Ø± Ú©Ù†ÛŒØ¯.")
        
        avg_week = sum(views_week) / len(views_week)
        total_views = sum(views_week)
        
        result = (
            f"ğŸ“Š Ø¢Ù…Ø§Ø± Ø¨Ø§Ø²Ø¯ÛŒØ¯ Ú©Ø§Ù†Ø§Ù„:\n"
            f"- ØªØ¹Ø¯Ø§Ø¯ Ù¾Ø³Øªâ€ŒÙ‡Ø§ (7 Ø±ÙˆØ² Ø§Ø®ÛŒØ±): {posts_count}\n"
            f"- Ù…Ø¬Ù…ÙˆØ¹ Ø¨Ø§Ø²Ø¯ÛŒØ¯Ù‡Ø§: {total_views}\n"
            f"- Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø§Ø²Ø¯ÛŒØ¯: {avg_week:.1f}"
        )
        await msg.edit_text(result, reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø²Ø¯ÛŒØ¯: {str(e)}")
        await msg.edit_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø§Ø²Ø¯ÛŒØ¯: {str(e)}", reply_markup=get_main_menu())

async def show_movies_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ show_movies")
    await query.answer()
    try:
        if not cached_movies:
            await query.message.edit_text("âŒ Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª", reply_markup=get_main_menu())
            return
        
        movies_list = "\n".join([f"{i+1}. {m['title']}" for i, m in enumerate(cached_movies)])
        keyboard = [[InlineKeyboardButton("Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data='back_to_main')]]
        reply_markup = InlineKeyboardMarkup(keyboard)
        await query.message.edit_text(f"ğŸ“‹ Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§:\n{movies_list}", reply_markup=reply_markup)
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± show_movies: {str(e)}")
        await query.message.edit_text(f"âŒ Ø®Ø·Ø§: {str(e)}", reply_markup=get_main_menu())

async def toggle_bot_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global bot_enabled
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ toggle_bot")
    await query.answer()
    try:
        bot_enabled = not bot_enabled
        status = "ÙØ¹Ø§Ù„" if bot_enabled else "ØºÛŒØ±ÙØ¹Ø§Ù„"
        await query.message.edit_text(f"âœ… Ø±Ø¨Ø§Øª {status} Ø´Ø¯", reply_markup=get_main_menu())
        await send_admin_alert(context, f"ğŸ¤– Ø±Ø¨Ø§Øª {status} Ø´Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± toggle_bot: {str(e)}")
        await msg.edit_text(f"âŒ Ø®Ø·Ø§: {str(e)}", reply_markup=get_main_menu())

async def reset_webhook_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    logger.info("Ø¯Ú©Ù…Ù‡ reset_webhook")
    await query.answer()
    msg = await query.message.edit_text("Ø¯Ø± Ø­Ø§Ù„ Ø±ÛŒØ³Øª Webhook...")
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/deleteWebhook",
                json={"drop_pending_updates": True}
            ) as response:
                result = await response.json()
                if result.get('ok'):
                    await msg.edit_text("âœ… Webhook Ø±ÛŒØ³Øª Ø´Ø¯", reply_markup=get_main_menu())
                else:
                    await msg.edit_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±ÛŒØ³Øª Webhook: {result.get('description')}", reply_markup=get_main_menu())
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±ÛŒØ³Øª Webhook: {e}")
        await msg.edit_text(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±ÛŒØ³Øª Webhook: {str(e)}", reply_markup=get_main_menu())

async def auto_post(context: ContextTypes.DEFAULT_TYPE):
    logger.info("Ø´Ø±ÙˆØ¹ Ù¾Ø³Øª Ø®ÙˆØ¯Ú©Ø§Ø±...")
    try:
        if not bot_enabled:
            logger.info("Ù¾Ø³Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ú©Ù†Ø³Ù„ Ø´Ø¯: Ø±Ø¨Ø§Øª ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª")
            return
        movie = await get_random_movie()
        if not movie:
            logger.error("Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯")
            await send_admin_alert(context, "âŒ Ø®Ø·Ø§: ÙÛŒÙ„Ù… Ø¨Ø±Ø§ÛŒ Ù¾Ø³Øª Ø®ÙˆØ¯Ú©Ø§Ø± ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return
        
        logger.info(f"ÙÛŒÙ„Ù… Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {movie['title']}")
        if movie['poster']:
            await context.bot.send_photo(
                chat_id=CHANNEL_ID,
                photo=movie['poster'],
                caption=format_movie_post(movie),
                parse_mode='HTML',
                disable_notification=True
            )
        else:
            await context.bot.send_message(
                chat_id=CHANNEL_ID,
                text=format_movie_post(movie),
                parse_mode='HTML',
                disable_notification=True
            )
        logger.info(f"Ù¾Ø³Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø±Ø§ÛŒ {movie['title']} Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø®ÙˆØ¯Ú©Ø§Ø±: {e}")
        await send_admin_alert(context, f"âŒ Ø®Ø·Ø§ÛŒ Ù¾Ø³Øª Ø®ÙˆØ¯Ú©Ø§Ø±: {str(e)}")

async def health_check(request):
    return web.Response(text="OK")

async def run_web():
    logger.info(f"Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆØ± ÙˆØ¨ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª {PORT}...")
    app = web.Application()
    app.router.add_get('/health', health_check)
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, '0.0.0.0', PORT)
    await site.start()
    logger.info(f"Ø³Ø±ÙˆØ± ÙˆØ¨ Ø±ÙˆÛŒ Ù¾ÙˆØ±Øª {PORT} ÙØ¹Ø§Ù„ Ø´Ø¯")
    return runner

async def run_bot():
    logger.info("Ø´Ø±ÙˆØ¹ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…...")
    try:
        app = Application.builder().token(TELEGRAM_TOKEN).build()
        logger.info("Application Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Application: {str(e)}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ø¨Ø§Øª: {str(e)}")
        raise
    
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("debug", debug))
    app.add_handler(CommandHandler("resetwebhook", reset_webhook_handler))
    
    app.add_handler(CallbackQueryHandler(back_to_main, pattern='^back_to_main$'))
    app.add_handler(CallbackQueryHandler(tests_menu, pattern='^tests_menu$'))
    app.add_handler(CallbackQueryHandler(fetch_movies_handler, pattern='^fetch_movies$'))
    app.add_handler(CallbackQueryHandler(post_now_handler, pattern='^post_now$'))
    app.add_handler(CallbackQueryHandler(test_all_handler, pattern='^test_all$'))
    app.add_handler(CallbackQueryHandler(test_channel_handler, pattern='^test_channel$'))
    app.add_handler(CallbackQueryHandler(stats_handler, pattern='^stats$'))
    app.add_handler(CallbackQueryHandler(show_movies_handler, pattern='^show_movies$'))
    app.add_handler(CallbackQueryHandler(toggle_bot_handler, pattern='^toggle_bot$'))
    app.add_handler(CallbackQueryHandler(reset_webhook_handler, pattern='^reset_webhook$'))
    
    job_queue = app.job_queue
    if job_queue:
        logger.info("JobQueue ÙØ¹Ø§Ù„ Ø´Ø¯")
        job_queue.run_repeating(auto_post, interval=POST_INTERVAL, first=10)
        job_queue.run_repeating(auto_fetch_movies, interval=FETCH_INTERVAL, first=60)
    else:
        logger.error("JobQueue ÙØ¹Ø§Ù„ Ù†Ø´Ø¯ØŒ Ø±Ø¨Ø§Øª Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯")
        await send_admin_alert(None, "âŒ Ø®Ø·Ø§: JobQueue ÙØ¹Ø§Ù„ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø±Ø¨Ø§Øª Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯.")
        global bot_enabled
        bot_enabled = False
        raise Exception("JobQueue ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª")
    
    await app.initialize()
    await app.start()
    await app.updater.start_polling(drop_pending_updates=True)
    logger.info("Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
    return app

async def main():
    logger.info("Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡...")
    await load_cache_from_file()
    await load_posted_movies_from_file()
    if not await fetch_movies_to_cache():
        logger.error("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§ÙˆÙ„ÛŒÙ‡ Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/deleteWebhook",
                json={"drop_pending_updates": True}
            ) as response:
                result = await response.json()
                logger.info(f"Ø±ÛŒØ³Øª Webhook: {result}")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø±ÛŒØ³Øª Webhook Ø§ÙˆÙ„ÛŒÙ‡: {e}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±ÛŒØ³Øª Webhook Ø§ÙˆÙ„ÛŒÙ‡: {str(e)}")
    
    bot_app = await run_bot()
    web_runner = await run_web()
    
    try:
        while True:
            await asyncio.sleep(3600)
    except KeyboardInterrupt:
        logger.info("Ø®Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† Ø¨Ø§Øª...")
    finally:
        await bot_app.updater.stop()
        await bot_app.stop()
        await bot_app.shutdown()
        await web_runner.cleanup()

if __name__ == '__main__':
    asyncio.run(main())
