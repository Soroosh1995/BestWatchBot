import asyncio
import logging
import os
import random
import re
import urllib.parse
from datetime import datetime, timedelta
from typing import Dict, List, Optional

import aiohttp
import genai
import httpx
import telegram
from dotenv import load_dotenv
from openai import AsyncOpenAI
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
load_dotenv()

# Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§
BOT_TOKEN = os.getenv("BOT_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
TMDB_API_KEY = os.getenv("TMDB_API_KEY")
OMDB_API_KEY = os.getenv("OMDB_API_KEY")
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
CHANNEL_ID = os.getenv("CHANNEL_ID")
ADMIN_CHAT_ID = os.getenv("ADMIN_CHAT_ID")

# ØªÙ†Ø¸ÛŒÙ… APIÙ‡Ø§
genai.configure(api_key=GOOGLE_API_KEY)
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú˜Ø§Ù†Ø±Ù‡Ø§
GENRE_TRANSLATIONS = {
    "Action": "Ø§Ú©Ø´Ù†",
    "Adventure": "Ù…Ø§Ø¬Ø±Ø§Ø¬ÙˆÛŒÛŒ",
    "Animation": "Ø§Ù†ÛŒÙ…ÛŒØ´Ù†",
    "Comedy": "Ú©Ù…Ø¯ÛŒ",
    "Crime": "Ø¬Ù†Ø§ÛŒÛŒ",
    "Documentary": "Ù…Ø³ØªÙ†Ø¯",
    "Drama": "Ø¯Ø±Ø§Ù…",
    "Family": "Ø®Ø§Ù†ÙˆØ§Ø¯Ú¯ÛŒ",
    "Fantasy": "ÙØ§Ù†ØªØ²ÛŒ",
    "History": "ØªØ§Ø±ÛŒØ®ÛŒ",
    "Horror": "ØªØ±Ø³Ù†Ø§Ú©",
    "Music": "Ù…ÙˆØ³ÛŒÙ‚ÛŒ",
    "Mystery": "Ø±Ø§Ø²Ø¢Ù„ÙˆØ¯",
    "Romance": "Ø¹Ø§Ø´Ù‚Ø§Ù†Ù‡",
    "Science Fiction": "Ø¹Ù„Ù…ÛŒ-ØªØ®ÛŒÙ„ÛŒ",
    "Thriller": "Ù‡ÛŒØ¬Ø§Ù†â€ŒØ§Ù†Ú¯ÛŒØ²",
    "War": "Ø¬Ù†Ú¯ÛŒ",
    "Western": "ÙˆØ³ØªØ±Ù†"
}

# ÙØ§Ù„â€ŒØ¨Ú© Ù†Ø¸Ø±Ø§Øª
FALLBACK_COMMENTS = {
    "Ø§Ù†ÛŒÙ…ÛŒØ´Ù†": [
        "Ø§ÛŒÙ† Ø§Ù†ÛŒÙ…ÛŒØ´Ù† Ø¨Ø§ Ø¬Ù„ÙˆÙ‡â€ŒÙ‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ø®ÛŒØ±Ù‡â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ùˆ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ù¾Ø±Ù…ØºØ²ØŒ ØªØ¬Ø±Ø¨Ù‡â€ŒØ§ÛŒ Ø¨Ù‡â€ŒÛŒØ§Ø¯Ù…Ø§Ù†Ø¯Ù†ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø³Ù†ÛŒÙ† Ø®Ù„Ù‚ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø´Ø®ØµÛŒØªâ€ŒÙ¾Ø±Ø¯Ø§Ø²ÛŒ Ø¹Ù…ÛŒÙ‚ Ùˆ Ù…ÙˆØ³ÛŒÙ‚ÛŒ Ù…ØªÙ† Ø¯Ù„â€ŒØ§Ù†Ú¯ÛŒØ²ØŒ Ù…Ø®Ø§Ø·Ø¨ Ø±Ø§ Ø¨Ù‡ Ø¯Ù†ÛŒØ§ÛŒÛŒ Ø®ÛŒØ§Ù„ÛŒ Ù…ÛŒâ€ŒØ¨Ø±Ø¯. Ø¯Ø± Ù†Ù‡Ø§ÛŒØªØŒ Ù¾ÛŒØ§Ù…ÛŒ Ø§Ù„Ù‡Ø§Ù…â€ŒØ¨Ø®Ø´ Ø§Ø² Ø§Ù…ÛŒØ¯ Ùˆ Ø´Ø¬Ø§Ø¹Øª Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.",
        "Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø³Ø±Ø´Ø§Ø± Ø§Ø² Ù…Ø§Ø¬Ø±Ø§ Ùˆ Ø·Ù†Ø² Ú©Ù‡ Ù‚Ù„Ø¨ Ù‡Ø± Ø¨ÛŒÙ†Ù†Ø¯Ù‡â€ŒØ§ÛŒ Ø±Ø§ ØªØ³Ø®ÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø§Ù†ÛŒÙ…ÛŒØ´Ù†â€ŒÙ‡Ø§ÛŒ Ø±Ù†Ú¯Ø§Ø±Ù†Ú¯ Ùˆ Ø¯ÛŒØ§Ù„ÙˆÚ¯â€ŒÙ‡Ø§ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø§Ù†Ù‡ØŒ Ù„Ø­Ø¸Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ù¾Ø± Ø§Ø² Ø®Ù†Ø¯Ù‡ Ùˆ ØªØ£Ù…Ù„ Ù…ÛŒâ€ŒØ³Ø§Ø²Ù†Ø¯. Ø§Ø«Ø±ÛŒ Ú©Ù‡ Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ø±Ø§ Ø¨Ø§ Ø¸Ø±Ø§ÙØª Ù…Ù†ØªÙ‚Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."
    ],
    "default": [
        "Ø§ÛŒÙ† ÙÛŒÙ„Ù… Ø¨Ø§ Ø±ÙˆØ§ÛŒØªÛŒ Ú¯ÛŒØ±Ø§ Ùˆ Ø¨Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®Ø´Ø§Ù†ØŒ Ø¨ÛŒÙ†Ù†Ø¯Ù‡ Ø±Ø§ Ø¨Ù‡ Ø³ÙØ±ÛŒ Ø§Ø­Ø³Ø§Ø³ÛŒ Ø¯Ø¹ÙˆØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ú©Ø§Ø±Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ù‡Ù†Ø±Ù…Ù†Ø¯Ø§Ù†Ù‡ Ùˆ ÙÛŒÙ„Ù…â€ŒØ¨Ø±Ø¯Ø§Ø±ÛŒ Ù†ÙØ³â€ŒÚ¯ÛŒØ±ØŒ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ Ø¹Ù…ÛŒÙ‚ Ø±Ø§ Ø¨Ù‡ ØªØµÙˆÛŒØ± Ù…ÛŒâ€ŒÚ©Ø´Ø¯. Ø§Ø«Ø±ÛŒ Ú©Ù‡ ØªØ§ Ù…Ø¯Øªâ€ŒÙ‡Ø§ Ø¯Ø± Ø°Ù‡Ù† Ù…Ø®Ø§Ø·Ø¨ Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯.",
        "ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø³ØªØ§Ø¯Ø§Ù†Ù‡ Ø§Ø² Ù‡ÛŒØ¬Ø§Ù† Ùˆ Ø§Ø­Ø³Ø§Ø³ Ú©Ù‡ Ø¨Ø§ Ù¾ÛŒÚ†Ø´â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø³ØªØ§Ù†ÛŒ ØºØ§ÙÙ„Ú¯ÛŒØ±Ú©Ù†Ù†Ø¯Ù‡ Ù‡Ù…Ø±Ø§Ù‡ Ø§Ø³Øª. Ø´Ø®ØµÛŒØªâ€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ù„Ø§ÛŒÙ‡ Ùˆ Ø¯ÛŒØ§Ù„ÙˆÚ¯â€ŒÙ‡Ø§ÛŒ ØªØ£Ø«ÛŒØ±Ú¯Ø°Ø§Ø±ØŒ ØªØ¬Ø±Ø¨Ù‡â€ŒØ§ÛŒ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø®Ù„Ù‚ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯. ÙÛŒÙ„Ù…ÛŒ Ú©Ù‡ Ø§Ø±Ø²Ø´ ØªÙ…Ø§Ø´Ø§ÛŒ Ú†Ù†Ø¯Ø¨Ø§Ø±Ù‡ Ø¯Ø§Ø±Ø¯."
    ]
}

# Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø¬Ù‡Ø§Ù†ÛŒ
posted_movies: List[str] = []
previous_comments: List[str] = []
api_availability = {
    "tmdb": True,
    "omdb": True,
    "gemini": True,
    "groq": True,
    "deepseek": True,
    "openai": True
}
api_errors = {"tmdb": 0, "omdb": 0}
min_chars, max_chars = 300, 500

# ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
def is_farsi(text: str) -> bool:
    farsi_chars = r'[\u0600-\u06FF]'
    return bool(re.search(farsi_chars, text))

def get_fallback_by_genre(comments: Dict[str, List[str]], genres: Optional[List[str]]) -> str:
    if genres and "Ø§Ù†ÛŒÙ…ÛŒØ´Ù†" in genres:
        return random.choice(comments["Ø§Ù†ÛŒÙ…ÛŒØ´Ù†"])
    return random.choice(comments["default"])

def limit_text_length(text: str, min_chars: int = 300, max_chars: int = 500) -> str:
    text = text.strip()
    text = re.sub(r'\s+', ' ', text.replace('\u200C', ' ').replace('\u200F', ' '))
    if len(text) > max_chars:
        shortened = text[:max_chars]
        last_period = shortened.rfind('.')
        if last_period > min_chars:
            text = shortened[:last_period + 1]
        else:
            text = shortened[:max_chars].strip() + '...'
    if len(text) < min_chars:
        logger.warning(f"Ù…ØªÙ† Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª: {len(text)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
    return text

async def make_api_request(url: str, retries: int = 3) -> Optional[Dict]:
    for attempt in range(retries):
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(url)
                response.raise_for_status()
                return response.json()
        except httpx.HTTPStatusError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ HTTP Ø¯Ø± {url}: {str(e)}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(2 ** attempt)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ {url}: {str(e)}")
            return None
    return None

async def post_api_request(url: str, data: Dict, headers: Dict, retries: int = 3) -> Optional[Dict]:
    for attempt in range(retries):
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(url, json=data, headers=headers)
                response.raise_for_status()
                return response.json()
        except httpx.HTTPStatusError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ HTTP Ø¯Ø± {url}: {str(e)}")
            if attempt == retries - 1:
                return None
            await asyncio.sleep(2 ** attempt)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª POST Ø¨Ù‡ {url}: {str(e)}")
            return None
    return None

async def get_imdb_score_tmdb(title: str, genres: Optional[List[str]] = None) -> Optional[str]:
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª TMDB Ø¨Ø±Ø§ÛŒ: {title}")
    encoded_title = urllib.parse.quote(title)
    url = f"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={encoded_title}&language=en-US"
    data = await make_api_request(url)
    if not data or not data.get('results'):
        logger.warning(f"TMDB Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯")
        api_errors['tmdb'] += 1
        return None
    movie = data['results'][0]
    imdb_score = movie.get('vote_average', 0)
    
    is_animation = False
    if genres:
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    else:
        details_url = f"https://api.themoviedb.org/3/movie/{movie.get('id')}?api_key={TMDB_API_KEY}&language=en-US"
        details_data = await make_api_request(details_url)
        genres = [GENRE_TRANSLATIONS.get(g['name'], 'Ø³Ø§ÛŒØ±') for g in details_data.get('genres', [])]
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    
    min_score = 8.0 if is_animation else 6.0
    if imdb_score < min_score:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯ (Ø­Ø¯Ø§Ù‚Ù„ {min_score} Ù„Ø§Ø²Ù… Ø§Ø³Øª)")
        return None
    api_errors['tmdb'] = 0
    return f"{float(imdb_score):.1f}/10"

async def get_imdb_score_omdb(title: str, genres: Optional[List[str]] = None) -> Optional[str]:
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª OMDb Ø¨Ø±Ø§ÛŒ: {title}")
    encoded_title = urllib.parse.quote(title)
    url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={encoded_title}&type=movie"
    data = await make_api_request(url)
    if not data or data.get('Response') == 'False':
        logger.warning(f"OMDb Ù‡ÛŒÚ† Ù†ØªÛŒØ¬Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {title} Ù†Ø¯Ø§Ø¯: {data.get('Error')}")
        api_errors['omdb'] += 1
        return None
    imdb_score = data.get('imdbRating', '0')
    
    is_animation = False
    if genres:
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    else:
        genres = data.get('Genre', '').split(', ')
        genres = [GENRE_TRANSLATIONS.get(g.strip(), 'Ø³Ø§ÛŒØ±') for g in genres]
        is_animation = 'Ø§Ù†ÛŒÙ…ÛŒØ´Ù†' in genres
    
    min_score = 8.0 if is_animation else 6.0
    if float(imdb_score) < min_score:
        logger.warning(f"ÙÛŒÙ„Ù… {title} Ø§Ù…ØªÛŒØ§Ø² {imdb_score} Ø¯Ø§Ø±Ø¯ØŒ Ø±Ø¯ Ø´Ø¯ (Ø­Ø¯Ø§Ù‚Ù„ {min_score} Ù„Ø§Ø²Ù… Ø§Ø³Øª)")
        return None
    api_errors['omdb'] = 0
    return f"{float(imdb_score):.1f}/10"

async def generate_comment(genres: Optional[List[str]] = None) -> str:
    logger.info("ØªÙˆÙ„ÛŒØ¯ ØªØ­Ù„ÛŒÙ„...")

    # 1. Gemini
    if api_availability['gemini']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ Gemini")
        try:
            async with asyncio.timeout(10):
                model = genai.GenerativeModel('gemini-1.5-flash')
                prompt = "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."
                response = await model.generate_content_async(prompt)
                text = response.text.strip()
                text = limit_text_length(text)
                logger.info(f"ØªØ­Ù„ÛŒÙ„ Gemini: {text}")
                logger.info(f"Ø·ÙˆÙ„ Ù…ØªÙ†: {len(text)}, ÙØ§Ø±Ø³ÛŒ: {is_farsi(text)}")
                if min_chars <= len(text) <= max_chars and is_farsi(text):
                    previous_comments.append(text)
                    if len(previous_comments) > 10:
                        previous_comments.pop(0)
                    logger.info("ØªØ­Ù„ÛŒÙ„ Gemini Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    return text
                logger.warning(f"ØªØ­Ù„ÛŒÙ„ Gemini Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
        except genai.exceptions.ResourceExhausted:
            logger.error("Ø®Ø·Ø§: ØªÙˆÚ©Ù† Gemini ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª")
            api_availability['gemini'] = False
            await send_admin_alert(None, "âŒ ØªÙˆÚ©Ù† Gemini ØªÙ…Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Gemini API: {str(e)}")
            api_availability['gemini'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Gemini: {str(e)}.")

    # 2. Groq
    if api_availability['groq']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ Groq")
        try:
            async with asyncio.timeout(10):
                url = "https://api.groq.com/openai/v1/chat/completions"
                headers = {
                    "Authorization": f"Bearer {GROQ_API_KEY}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "mistral-saba-24b",
                    "messages": [
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    "max_tokens": 200,
                    "temperature": 0.9
                }
                response = await post_api_request(url, data, headers, retries=3)
                if response and response.get('choices'):
                    text = response['choices'][0]['message']['content'].strip()
                    text = limit_text_length(text)
                    if min_chars <= len(text) <= max_chars and is_farsi(text):
                        previous_comments.append(text)
                        if len(previous_comments) > 10:
                            previous_comments.pop(0)
                        logger.info("ØªØ­Ù„ÛŒÙ„ Groq Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                        return text
                    logger.warning(f"ØªØ­Ù„ÛŒÙ„ Groq Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
                else:
                    logger.warning(f"Ù¾Ø§Ø³Ø® Groq Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {response}")
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Groq: {str(e)}")
            api_availability['groq'] = False
            await send_admin_alert(None, f"âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Groq: {str(e)}.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Groq API: {str(e)}")
            api_availability['groq'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Groq: {str(e)}.")

    # 3. DeepSeek
    if api_availability['deepseek']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ DeepSeek")
        try:
            async with asyncio.timeout(10):
                url = "https://api.deepseek.com/v1/chat/completions"
                headers = {
                    "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    "max_tokens": 200,
                    "temperature": 0.9
                }
                response = await post_api_request(url, data, headers, retries=3)
                if response and response.get('choices'):
                    text = response['choices'][0]['message']['content'].strip()
                    text = limit_text_length(text)
                    if min_chars <= len(text) <= max_chars and is_farsi(text):
                        previous_comments.append(text)
                        if len(previous_comments) > 10:
                            previous_comments.pop(0)
                        logger.info("ØªØ­Ù„ÛŒÙ„ DeepSeek Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                        return text
                    logger.warning(f"ØªØ­Ù„ÛŒÙ„ DeepSeek Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
                else:
                    logger.warning(f"Ù¾Ø§Ø³Ø® DeepSeek Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {response}")
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ DeepSeek: {str(e)}")
            api_availability['deepseek'] = False
            await send_admin_alert(None, f"âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ DeepSeek: {str(e)}.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± DeepSeek API: {str(e)}")
            api_availability['deepseek'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± DeepSeek: {str(e)}.")

    # 4. Open AI
    if api_availability['openai']:
        logger.info("ØªÙ„Ø§Ø´ Ø¨Ø§ Open AI")
        try:
            async with asyncio.timeout(10):
                response = await client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "You are a professional film critic writing in Persian."},
                        {"role": "user", "content": "ÛŒÚ© ØªØ­Ù„ÛŒÙ„ Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¬Ø°Ø§Ø¨ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ ÛŒÚ© ÙÛŒÙ„Ù… Ø¨Ù†ÙˆÛŒØ³ØŒ Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ù†Ø§Ù… ÙÛŒÙ„Ù…ØŒ Ø¨ÛŒÙ† 300 ØªØ§ 500 Ú©Ø§Ø±Ø§Ú©ØªØ±. Ù„Ø­Ù† Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ø³ÛŒÙ†Ù…Ø§ÛŒÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ Ùˆ Ù…ØªÙ† Ù…ØªÙ†ÙˆØ¹ Ùˆ Ù…ØªÙØ§ÙˆØª Ø§Ø² ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø´Ø¯. ÙÙ‚Ø· Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†."}
                    ],
                    max_tokens=200,
                    temperature=0.9
                )
                text = response.choices[0].message.content.strip()
                text = limit_text_length(text)
                if min_chars <= len(text) <= max_chars and is_farsi(text):
                    previous_comments.append(text)
                    if len(previous_comments) > 10:
                        previous_comments.pop(0)
                    logger.info("ØªØ­Ù„ÛŒÙ„ Open AI Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯")
                    return text
                logger.warning(f"ØªØ­Ù„ÛŒÙ„ Open AI Ù†Ø§Ù…Ø¹ØªØ¨Ø±: Ø·ÙˆÙ„={len(text)}, ÙØ§Ø±Ø³ÛŒ={is_farsi(text)}")
        except aiohttp.client_exceptions.ClientConnectorError as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Open AI: {str(e)}")
            api_availability['openai'] = False
            await send_admin_alert(None, f"âŒ Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø¨Ù‡ Open AI: {str(e)}.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Open AI API: {str(e)}")
            api_availability['openai'] = False
            await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Open AI: {str(e)}.")

    # 5. ÙØ§Ù„â€ŒØ¨Ú©
    logger.warning("Ù‡ÛŒÚ† ØªØ­Ù„ÛŒÙ„Ú¯Ø±ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙØ§Ù„â€ŒØ¨Ú©")
    comment = get_fallback_by_genre(FALLBACK_COMMENTS, genres)
    comment = limit_text_length(comment)
    previous_comments.append(comment)
    if len(previous_comments) > 10:
        previous_comments.pop(0)
    return comment

async def get_movie_info(title: str) -> Optional[Dict]:
    logger.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„Ù…: {title}")
    
    genres = None
    score = None
    
    if api_availability['tmdb'] and api_errors['tmdb'] < 3:
        logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ TMDB Ø¨Ø±Ø§ÛŒ {title}")
        score = await get_imdb_score_tmdb(title)
        if score:
            details_url = f"https://api.themoviedb.org/3/search/movie?api_key={TMDB_API_KEY}&query={urllib.parse.quote(title)}&language=fa-IR"
            data = await make_api_request(details_url)
            if data and data.get('results'):
                movie = data['results'][0]
                genres = [GENRE_TRANSLATIONS.get(g['name'], 'Ø³Ø§ÛŒØ±') for g in movie.get('genres', [])]
    
    if not score and api_availability['omdb'] and api_errors['omdb'] < 3:
        logger.info(f"ØªÙ„Ø§Ø´ Ø¨Ø§ OMDb Ø¨Ø±Ø§ÛŒ {title}")
        score = await get_imdb_score_omdb(title)
        if score and not genres:
            url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t={urllib.parse.quote(title)}&type=movie"
            data = await make_api_request(url)
            if data and data.get('Genre'):
                genres = [GENRE_TRANSLATIONS.get(g.strip(), 'Ø³Ø§ÛŒØ±') for g in data['Genre'].split(', ')]
    
    if not score:
        logger.error(f"Ù‡ÛŒÚ† Ø§Ù…ØªÛŒØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ {title} ÛŒØ§ÙØª Ù†Ø´Ø¯")
        return None
    
    if not genres:
        genres = ['Ø³Ø§ÛŒØ±']
    
    return {
        "title": title,
        "genres": genres,
        "score": score
    }

async def select_random_movie() -> Optional[Dict]:
    logger.info("Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÙ„Ù… ØªØµØ§Ø¯ÙÛŒ...")
    url = f"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=fa-IR&page=1"
    data = await make_api_request(url)
    
    if not data or not data.get('results'):
        logger.error("Ø¯Ø±ÛŒØ§ÙØª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨ Ø§Ø² TMDB Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
        return None
    
    movies = data['results']
    max_attempts = 10
    
    for attempt in range(max_attempts):
        movie = random.choice(movies)
        title = movie.get('title')
        if title in posted_movies:
            continue
        
        movie_info = await get_movie_info(title)
        if movie_info:
            logger.info(f"ÙÛŒÙ„Ù… Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {title} (ØªÙ„Ø§Ø´ {attempt + 1})")
            posted_movies.append(title)
            if len(posted_movies) > 100:
                posted_movies.pop(0)
            return movie_info
    
    logger.error("Ù‡ÛŒÚ† ÙÛŒÙ„Ù… Ù…Ù†Ø§Ø³Ø¨ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
    return None

async def send_admin_alert(update: Optional[Update], message: str):
    if not ADMIN_CHAT_ID:
        logger.warning("ADMIN_CHAT_ID ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
        return
    
    try:
        app = update.application if update else Application.builder().token(BOT_TOKEN).build()
        await app.bot.send_message(chat_id=ADMIN_CHAT_ID, text=message)
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù‡Ø´Ø¯Ø§Ø± Ø¨Ù‡ Ø§Ø¯Ù…ÛŒÙ†: {str(e)}")

async def run_tests(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    results = []

    # ØªØ³Øª TMDB
    tmdb_url = f"https://api.themoviedb.org/3/movie/popular?api_key={TMDB_API_KEY}&language=fa-IR&page=1"
    tmdb_data = await make_api_request(tmdb_url)
    tmdb_status = "âœ… TMDB Ø§ÙˆÚ©ÛŒ" if tmdb_data and tmdb_data.get('results') else f"âŒ TMDB Ø®Ø·Ø§: {tmdb_data}"
    results.append(tmdb_status)

    # ØªØ³Øª OMDb
    omdb_url = f"http://www.omdbapi.com/?apikey={OMDB_API_KEY}&t=Inception&type=movie"
    omdb_data = await make_api_request(omdb_url)
    omdb_status = "âœ… OMDb Ø§ÙˆÚ©ÛŒ" if omdb_data and omdb_data.get('Response') == 'True' else f"âŒ OMDb Ø®Ø·Ø§: {omdb_data.get('Error')}"
    results.append(omdb_status)

    # ØªØ³Øª JobQueue
    job_queue = context.job_queue
    results.append("âœ… JobQueue ÙØ¹Ø§Ù„" if job_queue else "âŒ JobQueue ØºÛŒØ±ÙØ¹Ø§Ù„")

    # ØªØ³Øª Gemini
    if api_availability['gemini']:
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            prompt = "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."
            response = await model.generate_content_async(prompt)
            text = response.text.strip()
            gemini_status = "âœ… Gemini Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else "âŒ Gemini Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
            results.append(gemini_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Gemini: {str(e)}")
            api_availability['gemini'] = False
            results.append(f"âŒ Gemini Ø®Ø·Ø§: {str(e)}")

    # ØªØ³Øª Groq
    if api_availability['groq']:
        try:
            url = "https://api.groq.com/openai/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": "mistral-saba-24b",
                "messages": [
                    {"role": "system", "content": "Write in Persian."},
                    {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                "max_tokens": 50,
                "temperature": 0.9
            }
            response = await post_api_request(url, data, headers, retries=3)
            text = response['choices'][0]['message']['content'].strip() if response and response.get('choices') else ""
            groq_status = "âœ… Groq Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else f"âŒ Groq Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± - Ù…ØªÙ† Ø¯Ø±ÛŒØ§ÙØªÛŒ: {text}"
            results.append(groq_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Groq: {str(e)}")
            api_availability['groq'] = False
            results.append(f"âŒ Groq Ø®Ø·Ø§: {str(e)}")

    # ØªØ³Øª DeepSeek
    if api_availability['deepseek']:
        try:
            url = "https://api.deepseek.com/v1/chat/completions"
            headers = {
                "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                "Content-Type": "application/json"
            }
            data = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": "Write in Persian."},
                    {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                "max_tokens": 50,
                "temperature": 0.9
            }
            response = await post_api_request(url, data, headers, retries=3)
            text = response['choices'][0]['message']['content'].strip() if response and response.get('choices') else ""
            deepseek_status = "âœ… DeepSeek Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else f"âŒ DeepSeek Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø± - Ù…ØªÙ† Ø¯Ø±ÛŒØ§ÙØªÛŒ: {text}"
            results.append(deepseek_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª DeepSeek: {str(e)}")
            api_availability['deepseek'] = False
            results.append(f"âŒ DeepSeek Ø®Ø·Ø§: {str(e)}")

    # ØªØ³Øª Open AI
    if api_availability['openai']:
        try:
            response = await client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Write in Persian."},
                    {"role": "user", "content": "ØªØ³Øª: ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ù†ÙˆÛŒØ³."}
                ],
                max_tokens=50,
                temperature=0.9
            )
            text = response.choices[0].message.content.strip()
            openai_status = "âœ… Open AI Ø§ÙˆÚ©ÛŒ" if text and is_farsi(text) else "âŒ Open AI Ø®Ø·Ø§: Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹ØªØ¨Ø±"
            results.append(openai_status)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Open AI: {str(e)}")
            api_availability['openai'] = False
            results.append(f"âŒ Open AI Ø®Ø·Ø§: {str(e)}")

    await update.message.reply_text("\n".join(results))

async def post_movie(context: ContextTypes.DEFAULT_TYPE) -> None:
    movie_info = await select_random_movie()
    if not movie_info:
        logger.error("Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯")
        await send_admin_alert(None, "âŒ Ù‡ÛŒÚ† ÙÛŒÙ„Ù…ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø´Ø¯!")
        return
    
    title = movie_info['title']
    genres = movie_info['genres']
    score = movie_info['score']
    
    comment = await generate_comment(genres)
    
    post_text = f"ğŸ¬ *{title}*\n\n"
    post_text += f"ğŸ“– Ú˜Ø§Ù†Ø±: {', '.join(genres)}\n"
    post_text += f"â­ Ø§Ù…ØªÛŒØ§Ø² IMDb: {score}\n\n"
    post_text += f"ğŸ’¬ *Ø­Ø±Ù Ù…Ø§*: {comment}"
    
    try:
        message = await context.bot.send_message(
            chat_id=CHANNEL_ID,
            text=post_text,
            parse_mode=telegram.constants.ParseMode.MARKDOWN
        )
        logger.info(f"Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª Ø¨Ø±Ø§ÛŒ: {title}")
        
        posted_movies.append(str(message.message_id))
        logger.info(f"Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {len(posted_movies)} ÙÛŒÙ„Ù…")
        logger.info(f"ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„â€ŒØ´Ø¯Ù‡: {posted_movies[-2:]}")
    except telegram.error.TimedOut:
        logger.error("Ø®Ø·Ø§ÛŒ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ù‡Ù†Ú¯Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª")
        await send_admin_alert(None, "âŒ Ø®Ø·Ø§ÛŒ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ù‡Ù†Ú¯Ø§Ù… Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª!")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª: {str(e)}")
        await send_admin_alert(None, f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾Ø³Øª: {str(e)}.")

async def immediate_post(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await post_movie(context)
    await update.message.reply_text("âœ… Ù¾Ø³Øª ÙÙˆØ±ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯!")

async def error_handler(update: Optional[Update], context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.error(f"Ø®Ø·Ø§ Ø±Ø® Ø¯Ø§Ø¯: {context.error}")
    await send_admin_alert(update, f"âŒ Ø®Ø·Ø§ÛŒ Ø¨Ø§Øª: {context.error}")

def main() -> None:
    # ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ù…ÙˆÙ‚Øª DeepSeek Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø®Ø·Ø§ÛŒ 402
    # api_availability['deepseek'] = False  # Ø§ÛŒÙ† Ø®Ø· Ø±Ùˆ Ø§Ú¯Ù‡ Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ DeepSeek Ú©Ø§Ø± Ú©Ù†Ù‡ØŒ Ø§Ø² Ú©Ø§Ù…Ù†Øª Ø¯Ø±Ø¨ÛŒØ§Ø±

    application = Application.builder().token(BOT_TOKEN).build()
    
    application.add_handler(CommandHandler("test", run_tests))
    application.add_handler(CommandHandler("post", immediate_post))
    application.add_error_handler(error_handler)
    
    job_queue = application.job_queue
    job_queue.run_repeating(post_movie, interval=24*60*60, first=10)
    
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
